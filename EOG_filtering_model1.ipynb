{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(fileDir, minCount, maxCount, leftLight):\n",
    "    userHp1 = []\n",
    "    userLp1 = []\n",
    "    userLhpl1 = []\n",
    "    userLlpl1 = []\n",
    "    userHpl1 = []\n",
    "    userLpl1 = []\n",
    "    userLhpg1 = []\n",
    "    userLlpg1 = []\n",
    "    userRhpg1 = []\n",
    "    userRlpg1 = []\n",
    "    userBlink1 = []\n",
    "    userNotBlink1 = []\n",
    "    \n",
    "    for count in range(minCount, maxCount):\n",
    "        file = open(fileDir + '/file' + str(count) + '-' + str(leftLight) + '.txt', 'r')\n",
    "        x = file.read()\n",
    "        file.close()\n",
    "    \n",
    "        x = x.split(',')\n",
    "    \n",
    "        data1 = []\n",
    "    \n",
    "        for index, item in enumerate(x):\n",
    "            data1.append(float(item))\n",
    "        \n",
    "        for index, item in enumerate(x):\n",
    "            if(index != len(data1) -1):\n",
    "                data1[index] = data1[index + 1]\n",
    "            \n",
    "        temp = 0\n",
    "        index = 0\n",
    "\n",
    "        start1 = []\n",
    "        middle1 = []\n",
    "        finish1 = []\n",
    "\n",
    "        for i in range(0, len(data1)):\n",
    "            if((temp + 150 < i) and (data1[i] > 100)):\n",
    "                for j in range(i, 0, -1):\n",
    "                    if(data1[j] <= 0):\n",
    "                        start1.append(j)\n",
    "                        break\n",
    "                \n",
    "                for j in range(start1[index] + 1, len(data1)):\n",
    "                    if(data1[j] <= 0):\n",
    "                        middle1.append(j)\n",
    "                        break\n",
    "                \n",
    "                for j in range(middle1[index] + 1, len(data1)):\n",
    "                    if(data1[j] >= 0):\n",
    "                        finish1.append(j)\n",
    "                        break\n",
    "                \n",
    "                i = finish1[index]\n",
    "                index = index + 1\n",
    "                temp = i\n",
    "   \n",
    "        temp = 0\n",
    "    \n",
    "        hp1 = []\n",
    "        lp1 = []\n",
    "        lhpl1 = []\n",
    "        llpl1 = []\n",
    "        hpl1 = []\n",
    "        lpl1 = []\n",
    "        lhpg1 = []\n",
    "        llpg1 = []\n",
    "        rhpg1 = []\n",
    "        rlpg1 = []\n",
    "        blink1 = []\n",
    "        notBlink1 = []\n",
    "    \n",
    "        index = 0;\n",
    "    \n",
    "        for i in range(start1[0], finish1[len(finish1) - 1]):\n",
    "            hp1.append(0)\n",
    "            lp1.append(0)\n",
    "            lhpl1.append(0)\n",
    "            llpl1.append(0)\n",
    "            hpl1.append(0)\n",
    "            lpl1.append(0)\n",
    "            lhpg1.append(0)\n",
    "            llpg1.append(0)\n",
    "            rhpg1.append(0)\n",
    "            rlpg1.append(0)\n",
    "            blink1.append(0)\n",
    "            notBlink1.append(0)\n",
    "    \n",
    "            for j in range(start1[index], finish1[index]):\n",
    "                if(hp1[index] < data1[j]):\n",
    "                    hp1[index] = data1[j]\n",
    "                    lhpl1[index] = j - start1[index]\n",
    "    \n",
    "            for j in range(start1[index], finish1[index]):\n",
    "                if(hp1[index] > data1[j]):\n",
    "                    lp1[index] = data1[j]\n",
    "                    llpl1[index] = j - start1[index]\n",
    "            \n",
    "            hpl1[index] = middle1[index] - start1[index]\n",
    "            lpl1[index] = finish1[index] - middle1[index]\n",
    "    \n",
    "            lhpg1[index] = hp1[index] / lhpl1[index]\n",
    "            llpg1[index] = lp1[index] / llpl1[index]\n",
    "            rhpg1[index] = hp1[index] / (hpl1[index] - lhpg1[index])\n",
    "            rlpg1[index] = lp1[index] / (lpl1[index] - llpl1[index])\n",
    "    \n",
    "            index = index + 1\n",
    "    \n",
    "            if(len(start1) == index):\n",
    "                break\n",
    "    \n",
    "            i = start1[index]\n",
    "        \n",
    "        index = 0;\n",
    "        \n",
    "        for i in range(0, len(finish1)):\n",
    "            blink1[i] = finish1[i] - start1[i]\n",
    "\n",
    "        for i in range(0, len(finish1) - 1):\n",
    "            notBlink1[i] = start1[i + 1] - finish1[i]\n",
    "        \n",
    "        for i in range(0, len(finish1)):\n",
    "            userHp1.append(hp1[i])\n",
    "            userLp1.append(lp1[i])\n",
    "            userLhpl1.append(lhpl1[i])\n",
    "            userLlpl1.append(llpl1[i])\n",
    "            userHpl1.append(hpl1[i])\n",
    "            userLpl1.append(lpl1[i])\n",
    "            userLhpg1.append(lhpg1[i])\n",
    "            userLlpg1.append(llpg1[i])\n",
    "            userRhpg1.append(rhpg1[i])\n",
    "            userRlpg1.append(rlpg1[i])\n",
    "            userBlink1.append(blink1[i])\n",
    "            userNotBlink1.append(notBlink1[i])\n",
    "            \n",
    "    return userHp1, userLp1, userLhpl1, userLlpl1, userHpl1, userLpl1, userLhpg1, userLlpg1, userRhpg1, userRlpg1, userBlink1, userNotBlink1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1Data  = []\n",
    "user1Label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp1, userLp1, userLhpl1, userLlpl1, userHpl1, userLpl1, userLhpg1, userLlpg1, userRhpg1, userRlpg1, userBlink1, userNotBlink1 = featureExtraction('C:/EOGData/user1', 0, 49, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp2, userLp2, userLhpl2, userLlpl2, userHpl2, userLpl2, userLhpg2, userLlpg2, userRhpg2, userRlpg2, userBlink2, userNotBlink2 = featureExtraction('C:/EOGData/user1', 0, 49, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = len(userHp1) +len(userHp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp1 = userHp1 + userHp2\n",
    "userLp1 = userLp1 + userLp2\n",
    "userLhpl1 = userLhpl1 + userLhpl2\n",
    "userLlpl1 = userLlpl1 + userLlpl2\n",
    "userHpl1 = userHpl1 + userHpl2\n",
    "userLpl1 = userLpl1 + userLpl2\n",
    "userLhpg1 = userLhpg1 + userLhpg2\n",
    "userLlpg1 = userLlpg1 + userLlpg2\n",
    "userRhpg1 = userRhpg1 + userRhpg2\n",
    "userRlpg1 = userRlpg1 + userRlpg2\n",
    "userBlink1 = userBlink1 + userBlink2\n",
    "userNotBlink1 = userNotBlink1 + userNotBlink2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, sum):\n",
    "    user1Data.append([userHp1[i], userLp1[i], userLhpl1[i], userLlpl1[i], userHpl1[i], userLpl1[i], userLhpg1[i], userLlpg1[i], userRhpg1[i], userRlpg1[i], userBlink1[i], userNotBlink1[i]])\n",
    "    user1Label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2Data  = []\n",
    "user2Label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp1, userLp1, userLhpl1, userLlpl1, userHpl1, userLpl1, userLhpg1, userLlpg1, userRhpg1, userRlpg1, userBlink1, userNotBlink1 = featureExtraction('C:/EOGData/user2', 0, 49, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp2, userLp2, userLhpl2, userLlpl2, userHpl2, userLpl2, userLhpg2, userLlpg2, userRhpg2, userRlpg2, userBlink2, userNotBlink2 = featureExtraction('C:/EOGData/user2', 0, 49, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = len(userHp1) +len(userHp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp1 = userHp1 + userHp2\n",
    "userLp1 = userLp1 + userLp2\n",
    "userLhpl1 = userLhpl1 + userLhpl2\n",
    "userLlpl1 = userLlpl1 + userLlpl2\n",
    "userHpl1 = userHpl1 + userHpl2\n",
    "userLpl1 = userLpl1 + userLpl2\n",
    "userLhpg1 = userLhpg1 + userLhpg2\n",
    "userLlpg1 = userLlpg1 + userLlpg2\n",
    "userRhpg1 = userRhpg1 + userRhpg2\n",
    "userRlpg1 = userRlpg1 + userRlpg2\n",
    "userBlink1 = userBlink1 + userBlink2\n",
    "userNotBlink1 = userNotBlink1 + userNotBlink2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, sum):\n",
    "    user2Data.append([userHp1[i], userLp1[i], userLhpl1[i], userLlpl1[i], userHpl1[i], userLpl1[i], userLhpg1[i], userLlpg1[i], userRhpg1[i], userRlpg1[i], userBlink1[i], userNotBlink1[i]])\n",
    "    user2Label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user3Data  = []\n",
    "user3Label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp1, userLp1, userLhpl1, userLlpl1, userHpl1, userLpl1, userLhpg1, userLlpg1, userRhpg1, userRlpg1, userBlink1, userNotBlink1 = featureExtraction('C:/EOGData/artifact/doridori', 0, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp2, userLp2, userLhpl2, userLlpl2, userHpl2, userLpl2, userLhpg2, userLlpg2, userRhpg2, userRlpg2, userBlink2, userNotBlink2 = featureExtraction('C:/EOGData/artifact/doridori', 0, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = len(userHp1) +len(userHp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHp1 = userHp1 + userHp2\n",
    "userLp1 = userLp1 + userLp2\n",
    "userLhpl1 = userLhpl1 + userLhpl2\n",
    "userLlpl1 = userLlpl1 + userLlpl2\n",
    "userHpl1 = userHpl1 + userHpl2\n",
    "userLpl1 = userLpl1 + userLpl2\n",
    "userLhpg1 = userLhpg1 + userLhpg2\n",
    "userLlpg1 = userLlpg1 + userLlpg2\n",
    "userRhpg1 = userRhpg1 + userRhpg2\n",
    "userRlpg1 = userRlpg1 + userRlpg2\n",
    "userBlink1 = userBlink1 + userBlink2\n",
    "userNotBlink1 = userNotBlink1 + userNotBlink2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, sum):\n",
    "    user3Data.append([userHp1[i], userLp1[i], userLhpl1[i], userLlpl1[i], userHpl1[i], userLpl1[i], userLhpg1[i], userLlpg1[i], userRhpg1[i], userRlpg1[i], userBlink1[i], userNotBlink1[i]])\n",
    "    user3Label.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1Data = np.array(user1Data)\n",
    "user2Data = np.array(user2Data)\n",
    "user3Data = np.array(user3Data)\n",
    "\n",
    "user1Label = np.array(user1Label)\n",
    "user2Label = np.array(user2Label)\n",
    "user3Label = np.array(user3Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((user1Data, user2Data, user3Data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.concatenate((user1Label, user2Label, user3Label), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3239"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(data.shape[0])\n",
    "np.random.shuffle(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[s]\n",
    "label = label[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempLabel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(label)):\n",
    "    if(label[i] == 0):\n",
    "        tempLabel.append([1, 0, 0])\n",
    "    elif(label[i] == 1):\n",
    "        tempLabel.append([0, 1, 0])\n",
    "    else:\n",
    "        tempLabel.append([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tempLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:2500]\n",
    "val_data = data[2500:]\n",
    "\n",
    "train_label = label[:2500]\n",
    "val_label = label[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "val_data -= mean\n",
    "val_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HongGi-hyeon\\anaconda3\\envs\\test_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HongGi-hyeon\\anaconda3\\envs\\test_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HongGi-hyeon\\anaconda3\\envs\\test_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HongGi-hyeon\\anaconda3\\envs\\test_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HongGi-hyeon\\anaconda3\\envs\\test_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HongGi-hyeon\\anaconda3\\envs\\test_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(actiFunc, lossFunc, hidden, node, dropout):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(node[0], activation=actiFunc, input_shape=(12, )))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    if(hidden == 2):\n",
    "        model.add(layers.Dense(node[1], activation=actiFunc))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    if(hidden == 3):\n",
    "        model.add(layers.Dense(node[1], activation=actiFunc))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Dense(node[2], activation=actiFunc))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop', loss=lossFunc, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.5588770220421648   acc max: 0.8687415407700855\n",
      "loss mean : 0.7187795711003234   acc mean: 0.7541813260921768\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3785533691291396   acc max: 0.8863328831605563\n",
      "loss mean : 0.5900493140714256   acc mean: 0.829269282370806\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4976076806349748   acc max: 0.8592692862021585\n",
      "loss mean : 0.6742535160213748   acc mean: 0.8065629242237593\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5044909763239395   acc max: 0.8714479034582558\n",
      "loss mean : 0.6498321520995867   acc mean: 0.822719891318933\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.54386003898187   acc max: 0.8673883687820745\n",
      "loss mean : 0.7005153401520642   acc mean: 0.7503247632588361\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.7103613861036236   acc max: 0.7077131169735982\n",
      "loss mean : 0.8665657711771085   acc mean: 0.6372259805775947\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.6541866336688299   acc max: 0.8213802505894507\n",
      "loss mean : 0.7813626562137566   acc mean: 0.6693910694824022\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6269488872630025   acc max: 0.8633288223301445\n",
      "loss mean : 0.8648741043057587   acc mean: 0.6999323402175804\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.700922951001437   acc max: 0.6644113755032561\n",
      "loss mean : 0.9890222575506433   acc mean: 0.5337618418580301\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.676297730538132   acc max: 0.6657645532984856\n",
      "loss mean : 0.8622893961316356   acc mean: 0.6081596747496455\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.8527713672879261   acc max: 0.6522327455035405\n",
      "loss mean : 1.0367628343292439   acc mean: 0.5466847089953286\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7968866856559527   acc max: 0.6400541251018663\n",
      "loss mean : 0.9502532995166573   acc mean: 0.5997564281327638\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.4109420112569858   acc max: 0.8714479007159582\n",
      "loss mean : 0.5875901182707656   acc mean: 0.8198105538712062\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.42315402901221033   acc max: 0.8660351860668404\n",
      "loss mean : 0.6991106553454359   acc mean: 0.7331664423261427\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5121371666213979   acc max: 0.86332882337867\n",
      "loss mean : 0.7004270696236737   acc mean: 0.7960487141027665\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5610805267571435   acc max: 0.8700947234853195\n",
      "loss mean : 0.7480521783381902   acc mean: 0.7870771309055883\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5239199132977383   acc max: 0.864682000125374\n",
      "loss mean : 0.7236403102110137   acc mean: 0.7882949927828307\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.6095016065566562   acc max: 0.8470906582994938\n",
      "loss mean : 0.8341657120158772   acc mean: 0.6778349109288401\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.606544475916758   acc max: 0.8511501960405962\n",
      "loss mean : 0.7789692012923335   acc mean: 0.7096617035908528\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6680696302563638   acc max: 0.8078484465046729\n",
      "loss mean : 0.8194137425246839   acc mean: 0.6615155619475612\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5851984252303798   acc max: 0.8592692743457542\n",
      "loss mean : 0.7911364575909987   acc mean: 0.8028552082354384\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6125316420653192   acc max: 0.8592692780559215\n",
      "loss mean : 0.8328924233455295   acc mean: 0.7258457367035467\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7816567395956171   acc max: 0.6535859291866442\n",
      "loss mean : 0.9102631440270739   acc mean: 0.6204194866872931\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6392275371635395   acc max: 0.8443843107746161\n",
      "loss mean : 0.757532881974206   acc mean: 0.7669012176780805\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.42576818319392945   acc max: 0.8755074431350977\n",
      "loss mean : 0.6548685947903438   acc mean: 0.7773748301009925\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.48846253345396584   acc max: 0.8673883660397769\n",
      "loss mean : 0.6707243716297357   acc mean: 0.8002977005853057\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.456068238321596   acc max: 0.8633288195071911\n",
      "loss mean : 0.6170228863649665   acc mean: 0.8155886323715739\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6094700548097148   acc max: 0.856562923513988\n",
      "loss mean : 0.7697240443086109   acc mean: 0.7630175908730544\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5431482750766171   acc max: 0.857916100260692\n",
      "loss mean : 0.703751639464066   acc mean: 0.7632746962019331\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.607026506180047   acc max: 0.8592692802336284\n",
      "loss mean : 0.8030380982023453   acc mean: 0.6858186745466174\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5990437616030805   acc max: 0.8741542664690495\n",
      "loss mean : 0.8019286281539881   acc mean: 0.7591474962637775\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6563886313702967   acc max: 0.8484438441603045\n",
      "loss mean : 0.810019415255651   acc mean: 0.7875372095311284\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6558211003814564   acc max: 0.8267929624156152\n",
      "loss mean : 0.8686379006452586   acc mean: 0.7288092026912955\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.7910549800354024   acc max: 0.6698240873294206\n",
      "loss mean : 0.9447062590569055   acc mean: 0.5858728010258833\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.668315732430702   acc max: 0.8552097403148192\n",
      "loss mean : 0.8058672568133461   acc mean: 0.7642083904675441\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6872523305219307   acc max: 0.8673883687820745\n",
      "loss mean : 0.8757441240379711   acc mean: 0.7769959392232245\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3683780833010099   acc max: 0.8822733418705982\n",
      "loss mean : 0.5646162146761388   acc mean: 0.8077672537600721\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.43111717366236635   acc max: 0.8782137992094915\n",
      "loss mean : 0.6296918094952634   acc mean: 0.8273207032039298\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.49948345211426526   acc max: 0.8673883594260002\n",
      "loss mean : 0.6404302996231673   acc mean: 0.8169553443680598\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6341445057253392   acc max: 0.8092016258323628\n",
      "loss mean : 0.756760011049988   acc mean: 0.7269012174615196\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4761629405057156   acc max: 0.8741542686467564\n",
      "loss mean : 0.7498447097247123   acc mean: 0.7096346422314082\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4836340377634046   acc max: 0.868741544399597\n",
      "loss mean : 0.6975491345953071   acc mean: 0.7445872798844345\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5869804168263695   acc max: 0.8470906561217869\n",
      "loss mean : 0.7794289010497004   acc mean: 0.7503788898653366\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5745987208996155   acc max: 0.8741542664690495\n",
      "loss mean : 0.7448628716338149   acc mean: 0.8330040585212357\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5898450544464411   acc max: 0.8673883622489537\n",
      "loss mean : 0.7710351950720619   acc mean: 0.781028418294148\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5484042805651044   acc max: 0.8606224623842716\n",
      "loss mean : 0.708885032849157   acc mean: 0.8207036537061042\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6181678801008749   acc max: 0.8294993142959068\n",
      "loss mean : 0.8248658163024865   acc mean: 0.6844384288517644\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6867904009773863   acc max: 0.8484438485157183\n",
      "loss mean : 0.8417472998287744   acc mean: 0.7102571038024673\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.4442236324285783   acc max: 0.8741542606618311\n",
      "loss mean : 0.6353855279922808   acc mean: 0.7888903919245459\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4456631525524253   acc max: 0.8782138033229379\n",
      "loss mean : 0.6106507454568544   acc mean: 0.8449391070435752\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.7441689304311802   acc max: 0.6684709095341911\n",
      "loss mean : 0.8128592727374644   acc mean: 0.6580784818751886\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.560776642436749   acc max: 0.8687415393989367\n",
      "loss mean : 0.6761113078047362   acc mean: 0.8170636005516143\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5376073074437607   acc max: 0.8633288142645633\n",
      "loss mean : 0.807752090457005   acc mean: 0.7423274706515796\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5233713836082747   acc max: 0.8592692845890422\n",
      "loss mean : 0.7809744154705248   acc mean: 0.715994587821309\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.6764772555340933   acc max: 0.6589986410128086\n",
      "loss mean : 0.8601647810039081   acc mean: 0.5832070357541028\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5694097627322309   acc max: 0.8565629224654625\n",
      "loss mean : 0.860728052007652   acc mean: 0.6846414091681028\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5140233231816789   acc max: 0.8497970241332409\n",
      "loss mean : 0.7137951211121148   acc mean: 0.7926657644668355\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6037656083319926   acc max: 0.833558854214716\n",
      "loss mean : 0.8692789240377036   acc mean: 0.6858322040133773\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6873937337905047   acc max: 0.8349120422532336\n",
      "loss mean : 0.9095299877462268   acc mean: 0.6878890403092958\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6880022243008078   acc max: 0.6576454691054534\n",
      "loss mean : 0.8309852661710628   acc mean: 0.6372936400750977\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.4295274128933237   acc max: 0.8741542592906822\n",
      "loss mean : 0.5926089968228857   acc mean: 0.8132205686094153\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.42996747148537023   acc max: 0.8755074420059162\n",
      "loss mean : 0.5988120463865535   acc mean: 0.7954127184742198\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4367246086607121   acc max: 0.8700947221141707\n",
      "loss mean : 0.5804887400968796   acc mean: 0.8477807841838133\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5719186970926267   acc max: 0.8660351846956916\n",
      "loss mean : 0.7017794909633708   acc mean: 0.8011502030503928\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4920774140925788   acc max: 0.8646820023030809\n",
      "loss mean : 0.7074293309917954   acc mean: 0.7770230049023931\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.46726528193211847   acc max: 0.8565629261756298\n",
      "loss mean : 0.690159890667834   acc mean: 0.7817050060351579\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.7529426677623847   acc max: 0.6644113630822611\n",
      "loss mean : 0.9321077394695177   acc mean: 0.5984709050233132\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.7350963345238578   acc max: 0.664411365259968\n",
      "loss mean : 0.8633345464900317   acc mean: 0.629864684762345\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.6188611070422584   acc max: 0.826792954350034\n",
      "loss mean : 0.7811508690673702   acc mean: 0.6663870103022083\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.573177998378893   acc max: 0.860622468272146\n",
      "loss mean : 0.7901365213344159   acc mean: 0.8106224643498536\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6570336272655224   acc max: 0.77266576656308\n",
      "loss mean : 0.848048097373507   acc mean: 0.6449661713435298\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7230168108365855   acc max: 0.8078484362613848\n",
      "loss mean : 0.8638673408000815   acc mean: 0.7128010815728824\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.4988879691280112   acc max: 0.8633288195071911\n",
      "loss mean : 0.6808938149904203   acc mean: 0.7759133969084011\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4365938164303848   acc max: 0.8619756409054035\n",
      "loss mean : 0.585971276311655   acc mean: 0.8305277404995667\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.49113121773941754   acc max: 0.8700947207430219\n",
      "loss mean : 0.6730329414443976   acc mean: 0.7846008129976438\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.47702158025701574   acc max: 0.8714479048294047\n",
      "loss mean : 0.5931460282746929   acc mean: 0.8505277402773601\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.43841526021170196   acc max: 0.872801078430532\n",
      "loss mean : 0.6518073619968674   acc mean: 0.829932339926211\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5811310014479538   acc max: 0.8606224623842716\n",
      "loss mean : 0.7350176530213416   acc mean: 0.788227335354956\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.759149973786087   acc max: 0.6657645474106114\n",
      "loss mean : 0.8697365714522916   acc mean: 0.6292286871605539\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6321545289237057   acc max: 0.7929634705125398\n",
      "loss mean : 0.8026721186583032   acc mean: 0.6997023015544929\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6257661764128121   acc max: 0.8294993304270691\n",
      "loss mean : 0.8438616999455492   acc mean: 0.6658863333883887\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6139605501830497   acc max: 0.8443843064192023\n",
      "loss mean : 0.8521471043788047   acc mean: 0.7457374837607428\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6559542230404762   acc max: 0.8322056823073608\n",
      "loss mean : 0.8001428638630534   acc mean: 0.7568200267700124\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6453597520620478   acc max: 0.8497970306663617\n",
      "loss mean : 0.8131451223417611   acc mean: 0.7706901217740993\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.40322443395248125   acc max: 0.8782138005806402\n",
      "loss mean : 0.6220632827995756   acc mean: 0.8066576459386835\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.5601287241395013   acc max: 0.8700947193718731\n",
      "loss mean : 0.6765617756051526   acc mean: 0.827510149061922\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4930171922192038   acc max: 0.8660351808242127\n",
      "loss mean : 0.6102910663943651   acc mean: 0.8256562916484833\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4805322324148857   acc max: 0.8714479034582558\n",
      "loss mean : 0.6075456912624013   acc mean: 0.8456021653654128\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5098069544090147   acc max: 0.8660351822760173\n",
      "loss mean : 0.7082978583075843   acc mean: 0.8190392421990516\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5671648473475073   acc max: 0.8619756504227892\n",
      "loss mean : 0.798449334981316   acc mean: 0.6987686059003917\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4818078998138521   acc max: 0.8728010821406993\n",
      "loss mean : 0.6774044360387793   acc mean: 0.8249661702732272\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6181699562621213   acc max: 0.8403247643226861\n",
      "loss mean : 0.8698486917783508   acc mean: 0.6639242215662268\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6322725422488821   acc max: 0.8511502084615912\n",
      "loss mean : 0.8415573967011275   acc mean: 0.6616102839774466\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5808175955476877   acc max: 0.8443843020637883\n",
      "loss mean : 0.7862714542402144   acc mean: 0.7467388371117059\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.8393215071687196   acc max: 0.6792963390743942\n",
      "loss mean : 1.1878614201903828   acc mean: 0.47281461421365023\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7314214439450162   acc max: 0.6549391135149945\n",
      "loss mean : 0.8768985857749019   acc mean: 0.6327875497707334\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.486970780666852   acc max: 0.8755074458773953\n",
      "loss mean : 0.7066794274334011   acc mean: 0.7671718556112301\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.41486580780781657   acc max: 0.8714479007159582\n",
      "loss mean : 0.5987814503754911   acc mean: 0.8151556146241655\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.48192378789872053   acc max: 0.8782137992094915\n",
      "loss mean : 0.6204527304717748   acc mean: 0.812882272414006\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.637357990135198   acc max: 0.8619756409054035\n",
      "loss mean : 0.7678016842653689   acc mean: 0.6934506086277219\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4624347191540895   acc max: 0.8633288223301445\n",
      "loss mean : 0.7005827042448343   acc mean: 0.7713396491394638\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5873364163348413   acc max: 0.8700947163069522\n",
      "loss mean : 0.7789422529492229   acc mean: 0.7474289580598896\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.6703000967170292   acc max: 0.853856566229757\n",
      "loss mean : 0.9171877250289078   acc mean: 0.6670906633045902\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.732834309460507   acc max: 0.6630581933526128\n",
      "loss mean : 0.8404741286699116   acc mean: 0.6215020302776879\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5876506106456658   acc max: 0.860622468272146\n",
      "loss mean : 0.8436110445602982   acc mean: 0.7436941818072281\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6541102209175068   acc max: 0.8633288282180187\n",
      "loss mean : 0.8597731284972617   acc mean: 0.7686738840890834\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7257114218116936   acc max: 0.6995940489117283\n",
      "loss mean : 0.9555037092541486   acc mean: 0.5423004065080973\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7283805341778653   acc max: 0.8267929602379083\n",
      "loss mean : 0.9848178399375391   acc mean: 0.6561975638449433\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.4208632588225224   acc max: 0.8728010793177459\n",
      "loss mean : 0.5669277039004921   acc mean: 0.8179025706370564\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.47200440678932026   acc max: 0.8606224634327972\n",
      "loss mean : 0.6474359131125539   acc mean: 0.7925710430547739\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4972702865268284   acc max: 0.8606224634327972\n",
      "loss mean : 0.7210072460907722   acc mean: 0.7788633279085002\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5172487505395293   acc max: 0.8646820008512763\n",
      "loss mean : 0.6525548512207316   acc mean: 0.8282543971392559\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5356431751838395   acc max: 0.8660351903415985\n",
      "loss mean : 0.7937534413915202   acc mean: 0.7517997305657772\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.551050245035969   acc max: 0.8592692765234611\n",
      "loss mean : 0.7591204827741614   acc mean: 0.7573883631006793\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.7673463088249806   acc max: 0.6644113587268473\n",
      "loss mean : 0.8653073254618819   acc mean: 0.6512719856692587\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.635256437713303   acc max: 0.8511502062838843\n",
      "loss mean : 0.7926179392920133   acc mean: 0.7481326114917641\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6718492247416299   acc max: 0.8362652163382958\n",
      "loss mean : 0.9172198832365754   acc mean: 0.7029093355529199\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6776157915995472   acc max: 0.7361299007606764\n",
      "loss mean : 0.8016902166451749   acc mean: 0.6619891739109373\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7653294700085713   acc max: 0.6603518253411589\n",
      "loss mean : 0.9870848979404718   acc mean: 0.5620838967264102\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6315984294443556   acc max: 0.8552097483804003\n",
      "loss mean : 0.8710011577630397   acc mean: 0.7119891737451897\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.5637420728016287   acc max: 0.864682006093904\n",
      "loss mean : 0.667187894158499   acc mean: 0.8352638704044406\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.41011180945436426   acc max: 0.8673883635394467\n",
      "loss mean : 0.5903483597129704   acc mean: 0.8120297698190635\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.54261613698709   acc max: 0.8728010845603736\n",
      "loss mean : 0.7079243757284382   acc mean: 0.8327740186468998\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5222455162318053   acc max: 0.8768606206077039\n",
      "loss mean : 0.6718744405309629   acc mean: 0.8175913383225947\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5677923268975037   acc max: 0.8673883607164933\n",
      "loss mean : 0.711635029942644   acc mean: 0.8197023014214104\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4935490499491298   acc max: 0.8619756401795011\n",
      "loss mean : 0.7446405736124079   acc mean: 0.7623680648437535\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.6605687759241974   acc max: 0.8592692882992096\n",
      "loss mean : 0.7895190981703939   acc mean: 0.7143437075393124\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6877228132926724   acc max: 0.8240866083576166\n",
      "loss mean : 0.8189638057427733   acc mean: 0.7461028424284457\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.612067234532275   acc max: 0.8470906685427819\n",
      "loss mean : 0.8366543188057992   acc mean: 0.7267388372500307\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.7351930144675207   acc max: 0.8322056844850677\n",
      "loss mean : 1.0567711256200472   acc mean: 0.5934641405157695\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6364340024000898   acc max: 0.8511502025737169\n",
      "loss mean : 0.8600694560173884   acc mean: 0.7431935036867979\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7963394788024551   acc max: 0.7388362687721304\n",
      "loss mean : 1.0402495646718715   acc mean: 0.6196887669975444\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.47663394483726307   acc max: 0.867388364668628\n",
      "loss mean : 0.6585750912724716   acc mean: 0.7894587280434909\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.571483986626136   acc max: 0.8673883632974793\n",
      "loss mean : 0.6858190215085616   acc mean: 0.795480379168655\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5139038940243856   acc max: 0.8714479020871071\n",
      "loss mean : 0.6596451576039981   acc mean: 0.8371447890761016\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5677313016619185   acc max: 0.8673883621682978\n",
      "loss mean : 0.7109552570286236   acc mean: 0.8167253041299658\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.48549467825276604   acc max: 0.872801076252825\n",
      "loss mean : 0.7086974950572312   acc mean: 0.7767658979870149\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5624870607914234   acc max: 0.8633288164422702\n",
      "loss mean : 0.7475891328535481   acc mean: 0.7172801078353909\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5787516574253088   acc max: 0.8552097424925261\n",
      "loss mean : 0.8278556013155695   acc mean: 0.719309877599205\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.572445424951623   acc max: 0.8579161061485662\n",
      "loss mean : 0.7689690621739635   acc mean: 0.7595534488340996\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.703688788962461   acc max: 0.8078484465046729\n",
      "loss mean : 1.0075327653249322   acc mean: 0.544682002793569\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.736228993280976   acc max: 0.6603518312290331\n",
      "loss mean : 0.8836405288035878   acc mean: 0.5937077118079298\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7282433960692647   acc max: 0.6725304429198795\n",
      "loss mean : 0.8954225624527112   acc mean: 0.6037618386838207\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7176396000691776   acc max: 0.7537212366986823\n",
      "loss mean : 0.8678553715295818   acc mean: 0.6415020293106245\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.4678225517272949   acc max: 0.8809201591553643\n",
      "loss mean : 0.6850360141724792   acc mean: 0.791596753152846\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4632658197044197   acc max: 0.8795669832958742\n",
      "loss mean : 0.5779056592077945   acc mean: 0.8502300416705411\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5105826415534916   acc max: 0.8633288247498189\n",
      "loss mean : 0.6873581201410746   acc mean: 0.7877401892657372\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6700086158893105   acc max: 0.6711772694800638\n",
      "loss mean : 0.8011355910789981   acc mean: 0.6321109595789962\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5358320496401703   acc max: 0.8619756423572081\n",
      "loss mean : 0.7212472231599412   acc mean: 0.7917050068761966\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5128934120454388   acc max: 0.8700947141292453\n",
      "loss mean : 0.8121919567344636   acc mean: 0.7074424893831451\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4669627906989019   acc max: 0.8700947184846591\n",
      "loss mean : 0.7067018920525969   acc mean: 0.7870636004253881\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5872302284421391   acc max: 0.8619756482450823\n",
      "loss mean : 0.7985981464337594   acc mean: 0.7576860620345571\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6497846966828642   acc max: 0.8322056903729419\n",
      "loss mean : 0.8838208292358136   acc mean: 0.6755886336725523\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6796267325403887   acc max: 0.85115020039601\n",
      "loss mean : 0.9404530647707565   acc mean: 0.6308660350661317\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7598475965498588   acc max: 0.6576454610398722\n",
      "loss mean : 0.9121974535119065   acc mean: 0.620514207546056\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7641335048275484   acc max: 0.6779431730549133\n",
      "loss mean : 0.963689589117312   acc mean: 0.6355480389210303\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.39242321994856344   acc max: 0.8768606192365551\n",
      "loss mean : 0.5824641280745299   acc mean: 0.8267658986455692\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.42546592457207355   acc max: 0.8728010820600435\n",
      "loss mean : 0.5870508522428421   acc mean: 0.8420838965776002\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5798814860506535   acc max: 0.8565629221428392\n",
      "loss mean : 0.7255408535234339   acc mean: 0.7564140731568105\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5180286219058727   acc max: 0.8673883621682978\n",
      "loss mean : 0.6753525429141378   acc mean: 0.7710960748819923\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5420840241428319   acc max: 0.8579161039708593\n",
      "loss mean : 0.7880623338654819   acc mean: 0.7500811902289461\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.6181661389838697   acc max: 0.8389715821720428\n",
      "loss mean : 0.8835545152264452   acc mean: 0.6761163739273285\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5423809185079695   acc max: 0.8525033803689464\n",
      "loss mean : 0.7658590746853444   acc mean: 0.7540866037600338\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6620389496521957   acc max: 0.8565629224654625\n",
      "loss mean : 0.8947360773499504   acc mean: 0.6955886337112669\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5148162179612662   acc max: 0.868741534156309\n",
      "loss mean : 0.7141121562004735   acc mean: 0.7732070358518982\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.7699494244119957   acc max: 0.6468200352098364\n",
      "loss mean : 0.9364788201810219   acc mean: 0.5970906650403034\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6631680897995326   acc max: 0.8200270706165144\n",
      "loss mean : 0.9620777447072031   acc mean: 0.6562516920197963\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.8277614600603571   acc max: 0.6481732114726055\n",
      "loss mean : 1.0519748917290581   acc mean: 0.4915967529697573\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.442586472376435   acc max: 0.8687415446415644\n",
      "loss mean : 0.5776638867910724   acc mean: 0.8269824091067818\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4651661159947051   acc max: 0.8660351821953615\n",
      "loss mean : 0.6047921216633065   acc mean: 0.8305683343021728\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.5439430325215175   acc max: 0.8646819994801275\n",
      "loss mean : 0.6561305338620171   acc mean: 0.7970365364762861\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.49846739447971805   acc max: 0.8579161037288918\n",
      "loss mean : 0.5982180711098711   acc mean: 0.8250067657260511\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4871591628001088   acc max: 0.8633288245078514\n",
      "loss mean : 0.7315592506047999   acc mean: 0.7773342344350356\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.44998880123898527   acc max: 0.8741542664690495\n",
      "loss mean : 0.6518847747826608   acc mean: 0.8060081191387164\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.516511325342568   acc max: 0.8700947163069522\n",
      "loss mean : 0.7302779678554755   acc mean: 0.8093910681354498\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.550406184748158   acc max: 0.8606224543186906\n",
      "loss mean : 0.7731638393406939   acc mean: 0.7647496607677858\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.7433144130790669   acc max: 0.8281461482764259\n",
      "loss mean : 1.0606893315278145   acc mean: 0.5694046007415358\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.7331065612974929   acc max: 0.844384298353621\n",
      "loss mean : 0.9024072569189276   acc mean: 0.6993098780726547\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.576342922102292   acc max: 0.8579160980829851\n",
      "loss mean : 0.8002883816047677   acc mean: 0.7577266574268896\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6916745162300554   acc max: 0.6698240873294206\n",
      "loss mean : 0.8845476209835045   acc mean: 0.5812990546879814\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.41031500160774775   acc max: 0.8782138019517891\n",
      "loss mean : 0.5830114616302419   acc mean: 0.8363599443653439\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.5163767432166372   acc max: 0.86332882337867\n",
      "loss mean : 0.6271306114485525   acc mean: 0.8253044655701303\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.46736237862435986   acc max: 0.8646820022224251\n",
      "loss mean : 0.5639568687412833   acc mean: 0.8346278751783666\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6493529573345055   acc max: 0.7239512818108069\n",
      "loss mean : 0.7693523856186897   acc mean: 0.6181596742636941\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4910244415835534   acc max: 0.8646820081909551\n",
      "loss mean : 0.6961471102992641   acc mean: 0.788078485757556\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.704419619498298   acc max: 0.7510148767528095\n",
      "loss mean : 0.8763632076785111   acc mean: 0.638173206671165\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5523619861499544   acc max: 0.8633288303957256\n",
      "loss mean : 0.8267404429160854   acc mean: 0.6966035183935512\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6777835149564988   acc max: 0.6617050009586815\n",
      "loss mean : 0.7743714656784668   acc mean: 0.6502976952926715\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.7436734687168963   acc max: 0.7807848464006985\n",
      "loss mean : 0.9437051121436855   acc mean: 0.6199729361726886\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6263513005312144   acc max: 0.8497970263109478\n",
      "loss mean : 0.7954499751289095   acc mean: 0.7764411368042593\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7265673872582483   acc max: 0.8240866024697424\n",
      "loss mean : 1.084146494179843   acc mean: 0.5326251701375467\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7517633257441334   acc max: 0.664411365259968\n",
      "loss mean : 0.9699155320632442   acc mean: 0.5954803792263239\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.46480815788083213   acc max: 0.8768606192365551\n",
      "loss mean : 0.6390965018470813   acc mean: 0.8301082557359152\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.32521813829632346   acc max: 0.8890392403641315\n",
      "loss mean : 0.49381720645703536   acc mean: 0.8492963451574557\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.44204862970299263   acc max: 0.8768606219788527\n",
      "loss mean : 0.5665691109217391   acc mean: 0.8583626518738288\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.44218587415628086   acc max: 0.8768606258503316\n",
      "loss mean : 0.6279180294347875   acc mean: 0.7911907997929033\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4845244477985676   acc max: 0.8741542584034684\n",
      "loss mean : 0.6893235821031911   acc mean: 0.7796346418521238\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4016005636390717   acc max: 0.8768606307703362\n",
      "loss mean : 0.5813860136347148   acc mean: 0.8360081185922733\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4365750494361408   acc max: 0.8687415363340159\n",
      "loss mean : 0.6053191761073627   acc mean: 0.8183085243393827\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.49050553145040837   acc max: 0.8606224704498528\n",
      "loss mean : 0.6850158092988521   acc mean: 0.8014208400297875\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5551650045850441   acc max: 0.8660351763881431\n",
      "loss mean : 0.7815655534443254   acc mean: 0.7746549381958937\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.508083485782711   acc max: 0.8646820044807878\n",
      "loss mean : 0.696531938697553   acc mean: 0.7852097417859811\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6607146393784974   acc max: 0.825439778087265\n",
      "loss mean : 0.8243691041198571   acc mean: 0.655818673702151\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5794723979997699   acc max: 0.8714478941021817\n",
      "loss mean : 0.8287876314481315   acc mean: 0.7591069013251339\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.36984047571925577   acc max: 0.8876860656338228\n",
      "loss mean : 0.5625396631087438   acc mean: 0.8467794334235148\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4093839404386177   acc max: 0.8809201605265131\n",
      "loss mean : 0.5621982763249914   acc mean: 0.8364817327285169\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4001985779473198   acc max: 0.8822733432417471\n",
      "loss mean : 0.5350225046938424   acc mean: 0.846265222830282\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.41494268683038643   acc max: 0.8795669832958742\n",
      "loss mean : 0.543393801376526   acc mean: 0.8600000010267486\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.46598408001201563   acc max: 0.8768606161716342\n",
      "loss mean : 0.6482306848867659   acc mean: 0.8328552080075863\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4243249160430428   acc max: 0.8782138063878587\n",
      "loss mean : 0.6247163294769914   acc mean: 0.8246143434736095\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.44192584102950655   acc max: 0.8741542686467564\n",
      "loss mean : 0.6776461336387672   acc mean: 0.7881596757348559\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5333106916231457   acc max: 0.875507446441986\n",
      "loss mean : 0.7064629506959967   acc mean: 0.828159674215704\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5302480972990776   acc max: 0.8728010821406993\n",
      "loss mean : 0.725553713030357   acc mean: 0.8092151565283173\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5017996533636473   acc max: 0.8714479065231767\n",
      "loss mean : 0.7350666404262449   acc mean: 0.7966170487937003\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5143548295365619   acc max: 0.8660351903415985\n",
      "loss mean : 0.8246034574145714   acc mean: 0.7184979703752208\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5488687001965205   acc max: 0.868741546577304\n",
      "loss mean : 0.8225120117949858   acc mean: 0.7340189430502738\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3171312560973858   acc max: 0.8863328817894075\n",
      "loss mean : 0.4985507645089991   acc mean: 0.842151555724654\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.31731035563394083   acc max: 0.8863328804182586\n",
      "loss mean : 0.5155374425629479   acc mean: 0.8460757778155467\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4301037452056379   acc max: 0.8795669832958742\n",
      "loss mean : 0.5776014804448907   acc mean: 0.8493640050417031\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.43619503232074525   acc max: 0.8714479020871071\n",
      "loss mean : 0.5808153372910252   acc mean: 0.8231123144337871\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.40987011403127677   acc max: 0.875507444264279\n",
      "loss mean : 0.609378305095297   acc mean: 0.8415832196875741\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4028831474755227   acc max: 0.8809201626235642\n",
      "loss mean : 0.618128303596712   acc mean: 0.8190663050133257\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4339755806613194   acc max: 0.8768606285926293\n",
      "loss mean : 0.5985751452683111   acc mean: 0.8396481742430604\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.49456517033389846   acc max: 0.8741542642913426\n",
      "loss mean : 0.7068175778087324   acc mean: 0.756008118245655\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5267916226580598   acc max: 0.8579160959052782\n",
      "loss mean : 0.7816263406888075   acc mean: 0.7238565614291232\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5335644039152763   acc max: 0.8579161024383989\n",
      "loss mean : 0.7084952876685597   acc mean: 0.7980784845920794\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5488449529478773   acc max: 0.864682000125374\n",
      "loss mean : 0.7622197107718666   acc mean: 0.7890257093616846\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5996639454316384   acc max: 0.8552097403148192\n",
      "loss mean : 0.8132899561617145   acc mean: 0.7251962106331115\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3009801668307778   acc max: 0.8849797043168013\n",
      "loss mean : 0.49066888833723465   acc mean: 0.8548985130389261\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4016978519695215   acc max: 0.8728010859315224\n",
      "loss mean : 0.5967126332548055   acc mean: 0.8125304458420396\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4597088097316164   acc max: 0.8809201632688107\n",
      "loss mean : 0.6006436923045428   acc mean: 0.8271718532907625\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4486869109015665   acc max: 0.8755074392636187\n",
      "loss mean : 0.5597950740789689   acc mean: 0.8507983769175972\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4584895583305694   acc max: 0.8795669782952139\n",
      "loss mean : 0.6515949055850909   acc mean: 0.8359539913683527\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.44666909792426474   acc max: 0.8849797025423733\n",
      "loss mean : 0.6538612870579644   acc mean: 0.7866305824807758\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4940798477407076   acc max: 0.8809201706891453\n",
      "loss mean : 0.671319518757931   acc mean: 0.823626522206486\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.504047602374757   acc max: 0.8619756504227892\n",
      "loss mean : 0.686528352621605   acc mean: 0.8191339667929849\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5828287346598583   acc max: 0.8633288303957256\n",
      "loss mean : 0.8124556548371206   acc mean: 0.7362110976804251\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5006142973254595   acc max: 0.8714478962798886\n",
      "loss mean : 0.7089119246380255   acc mean: 0.8053450611564401\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.5284782870696588   acc max: 0.8565629181100487\n",
      "loss mean : 0.7522296267683353   acc mean: 0.7684979709494902\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5671701761156683   acc max: 0.8606224580288578\n",
      "loss mean : 0.8532718324467681   acc mean: 0.7299458724437773\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.34768226049104467   acc max: 0.8917456030523019\n",
      "loss mean : 0.5080548603717788   acc mean: 0.8424221919333822\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.32804439899401994   acc max: 0.8876860590200463\n",
      "loss mean : 0.47528727855629144   acc mean: 0.8534912047770089\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.413214892794218   acc max: 0.8741542659044589\n",
      "loss mean : 0.5371008945346201   acc mean: 0.843247632629091\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.44207626399716443   acc max: 0.8714479020871071\n",
      "loss mean : 0.5681881671841477   acc mean: 0.8430717171750792\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4276797502063447   acc max: 0.8768606161716342\n",
      "loss mean : 0.5937307736749416   acc mean: 0.8195940427637393\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.49957829689624667   acc max: 0.8687415385117228\n",
      "loss mean : 0.6365035892210407   acc mean: 0.8274830843252161\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.40849931036022585   acc max: 0.872801076252825\n",
      "loss mean : 0.6181018834785938   acc mean: 0.8166035170847088\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.48907373641921315   acc max: 0.8782138063878587\n",
      "loss mean : 0.6363793989955493   acc mean: 0.8452773999240306\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5046995665288262   acc max: 0.8741542642913426\n",
      "loss mean : 0.8616335968179211   acc mean: 0.7385791621624375\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5281166089081151   acc max: 0.8592692802336284\n",
      "loss mean : 0.8437345146947366   acc mean: 0.6934776716378894\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5527893633093982   acc max: 0.8633288223301445\n",
      "loss mean : 0.7326982854627306   acc mean: 0.75008119079515\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5931894376732822   acc max: 0.8579161105039801\n",
      "loss mean : 0.7507408016694254   acc mean: 0.8120297707353135\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.32190622254218076   acc max: 0.8944519616270259\n",
      "loss mean : 0.5173932767474927   acc mean: 0.8552503383377408\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3258070158539025   acc max: 0.8876860590200463\n",
      "loss mean : 0.4970663963461922   acc mean: 0.8450879561344569\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.43762997857449987   acc max: 0.8714479045874373\n",
      "loss mean : 0.5456482627015958   acc mean: 0.8508254414853286\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.47219598781272104   acc max: 0.8728010834311922\n",
      "loss mean : 0.642473463318506   acc mean: 0.8056968870605766\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.40871421059187757   acc max: 0.875507442086572\n",
      "loss mean : 0.5633901308672515   acc mean: 0.8431393742311308\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.43502017367676565   acc max: 0.8782138020324449\n",
      "loss mean : 0.6470394199949479   acc mean: 0.8186874167344891\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.48827511471405083   acc max: 0.8660351866314311\n",
      "loss mean : 0.6195998708353314   acc mean: 0.826522326746071\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4271013488708233   acc max: 0.8836265262796044\n",
      "loss mean : 0.6378736304329439   acc mean: 0.8154668465805149\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.47188654037870476   acc max: 0.8822733484843749\n",
      "loss mean : 0.6628964760863247   acc mean: 0.8278619744841397\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.47749069893634366   acc max: 0.8714479043454698\n",
      "loss mean : 0.7300553958204666   acc mean: 0.7681732046870318\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5524616543914371   acc max: 0.8646820023030809\n",
      "loss mean : 0.6958451021120899   acc mean: 0.8282273345653357\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5699980500909085   acc max: 0.8700947221948265\n",
      "loss mean : 0.7298313924287104   acc mean: 0.822787549613858\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.34139862749347505   acc max: 0.8863328842897377\n",
      "loss mean : 0.517089522808024   acc mean: 0.83856562918473\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.35369429698009774   acc max: 0.8836265191012371\n",
      "loss mean : 0.5175690639402127   acc mean: 0.8444925592083571\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.41554796740069927   acc max: 0.8741542659044589\n",
      "loss mean : 0.5681407455730987   acc mean: 0.818173208633521\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4448253251460957   acc max: 0.8755074433770651\n",
      "loss mean : 0.5871182124496152   acc mean: 0.849702299908711\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38841922764687803   acc max: 0.8782137961445706\n",
      "loss mean : 0.6102118593248689   acc mean: 0.8279566961280871\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4850291386347501   acc max: 0.8768606183493411\n",
      "loss mean : 0.7045942634247312   acc mean: 0.7718267914402793\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4436908001748086   acc max: 0.8768606264149224\n",
      "loss mean : 0.6586621707266498   acc mean: 0.8241407310127892\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5027341992671177   acc max: 0.8633288303957256\n",
      "loss mean : 0.6784828048065326   acc mean: 0.8238159671736345\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.5378360958802684   acc max: 0.8579160937275713\n",
      "loss mean : 0.7849353094812337   acc mean: 0.7019350482402456\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4854488138900881   acc max: 0.8728010740751181\n",
      "loss mean : 0.7046416584177496   acc mean: 0.7619350454781874\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5841541688722912   acc max: 0.864682000125374\n",
      "loss mean : 0.7708896645843096   acc mean: 0.762949932782995\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5996938297003306   acc max: 0.8552097403148192\n",
      "loss mean : 0.7957073216251171   acc mean: 0.7354397819672127\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.38736344888019947   acc max: 0.8741542592906822\n",
      "loss mean : 0.5569609507970784   acc mean: 0.8202300401771986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3889563031222404   acc max: 0.8809201591553643\n",
      "loss mean : 0.5525035575379054   acc mean: 0.8585385674262404\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3876544197615493   acc max: 0.8822733457420773\n",
      "loss mean : 0.535405164821948   acc mean: 0.8511637358389623\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4273725419389702   acc max: 0.8728010820600435\n",
      "loss mean : 0.5432016051561649   acc mean: 0.8456968887970961\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.48144000397644765   acc max: 0.875507446441986\n",
      "loss mean : 0.6667283013842104   acc mean: 0.8161975648273314\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.45330618473125245   acc max: 0.86874154222189\n",
      "loss mean : 0.6200156199335245   acc mean: 0.82480378977904\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.48659438499739754   acc max: 0.8646820023030809\n",
      "loss mean : 0.6976622098385884   acc mean: 0.7428687423165179\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4591641690234209   acc max: 0.8660351742104361\n",
      "loss mean : 0.5958357886746223   acc mean: 0.8311502042320005\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4704512156878821   acc max: 0.8700947243725334\n",
      "loss mean : 0.7023987981366531   acc mean: 0.804181326832194\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5221731594999363   acc max: 0.8660351844537242\n",
      "loss mean : 0.7862391466200757   acc mean: 0.7161704999200382\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5256867528929601   acc max: 0.8660351800983104\n",
      "loss mean : 0.7139778775283223   acc mean: 0.7940730712809807\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5433601565225521   acc max: 0.8619756401795011\n",
      "loss mean : 0.7213271205157485   acc mean: 0.7893640045698668\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3569254043218409   acc max: 0.8863328790471099\n",
      "loss mean : 0.48631157199447633   acc mean: 0.868064953363797\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.36750750943352956   acc max: 0.8903924217082166\n",
      "loss mean : 0.4975773014468979   acc mean: 0.8580649509945323\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.40818535237092934   acc max: 0.8741542659044589\n",
      "loss mean : 0.5506304884783632   acc mean: 0.8299864699755051\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.49676804799026986   acc max: 0.8768606206077039\n",
      "loss mean : 0.6239726534981851   acc mean: 0.8282814611181999\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4947894987459918   acc max: 0.8700947243725334\n",
      "loss mean : 0.639826039554947   acc mean: 0.8186738815814943\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3949472498909869   acc max: 0.8782138042101518\n",
      "loss mean : 0.5890485133450473   acc mean: 0.8372395132242099\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4363017268126001   acc max: 0.8700947265502403\n",
      "loss mean : 0.6479219001471109   acc mean: 0.7964005424033885\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5723003569249371   acc max: 0.860622468272146\n",
      "loss mean : 0.7712774836476665   acc mean: 0.7254533153941729\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4837339055070374   acc max: 0.8673883703145349\n",
      "loss mean : 0.6981397673903043   acc mean: 0.7959539933545017\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5381424804501669   acc max: 0.8633288142645633\n",
      "loss mean : 0.718479085387977   acc mean: 0.8061299033174656\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4817271366493628   acc max: 0.8619756423572081\n",
      "loss mean : 0.6452018209005403   acc mean: 0.820378891373197\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5812780824823857   acc max: 0.860622468272146\n",
      "loss mean : 0.8061837917517907   acc mean: 0.7781867365012795\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3194140249885951   acc max: 0.8971583229440475\n",
      "loss mean : 0.5138498356079377   acc mean: 0.8422868734936912\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.39768599883145345   acc max: 0.8836265191012371\n",
      "loss mean : 0.5901371501835823   acc mean: 0.7991474975179755\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4114871454980925   acc max: 0.8809201646399595\n",
      "loss mean : 0.499284784398237   acc mean: 0.8679972939941331\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.43535043760952674   acc max: 0.8687415435123831\n",
      "loss mean : 0.5713212369299709   acc mean: 0.8380514214471164\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3826274157215681   acc max: 0.8863328803376028\n",
      "loss mean : 0.5644695686245481   acc mean: 0.8210554787986415\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3953740002337909   acc max: 0.8849797062525407\n",
      "loss mean : 0.5944722065289224   acc mean: 0.8205277392264148\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.4555998325993147   acc max: 0.8700947221948265\n",
      "loss mean : 0.6418555154848002   acc mean: 0.8194046027125619\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.45219699649268785   acc max: 0.8755074399088651\n",
      "loss mean : 0.6117656071760336   acc mean: 0.8370636001725319\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5590354661496308   acc max: 0.8552097424925261\n",
      "loss mean : 0.7841373187779412   acc mean: 0.709431664299255\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5760912057188754   acc max: 0.85115020039601\n",
      "loss mean : 0.8069126418737017   acc mean: 0.6810419485184674\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5455745096458311   acc max: 0.8714479021677629\n",
      "loss mean : 0.711470057681223   acc mean: 0.7939106886574797\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6129974479281692   acc max: 0.8579161024383989\n",
      "loss mean : 0.859819767446092   acc mean: 0.7223680646070284\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2909212574181279   acc max: 0.8849796990741735\n",
      "loss mean : 0.48604790808101134   acc mean: 0.8460757795972335\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.33102456219141474   acc max: 0.8836265191012371\n",
      "loss mean : 0.5390639181884764   acc mean: 0.8108254399952127\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.42381842763078714   acc max: 0.871447905958586\n",
      "loss mean : 0.5637514422815771   acc mean: 0.8373748324825574\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.435424186904311   acc max: 0.871447905958586\n",
      "loss mean : 0.594407146048804   acc mean: 0.8221786211368518\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.41668217426546533   acc max: 0.8782138004999844\n",
      "loss mean : 0.5982028350560689   acc mean: 0.8312178619086984\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.46193310759548245   acc max: 0.86874154222189\n",
      "loss mean : 0.7471699798784656   acc mean: 0.7317591346548278\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4776650207049147   acc max: 0.8673883563610795\n",
      "loss mean : 0.6221420193859785   acc mean: 0.8288903911458138\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4872675919565038   acc max: 0.872801076252825\n",
      "loss mean : 0.6371379116234018   acc mean: 0.8469418130538782\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5338599014024128   acc max: 0.868741544399597\n",
      "loss mean : 0.7882025711220237   acc mean: 0.7725710415876444\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.48659612288817017   acc max: 0.8768606183493411\n",
      "loss mean : 0.6804465384033277   acc mean: 0.8335047349063565\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5685608076468534   acc max: 0.8619756423572081\n",
      "loss mean : 0.7711083483534671   acc mean: 0.7732746972972387\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6496085383411351   acc max: 0.847090666365075\n",
      "loss mean : 0.799490869229153   acc mean: 0.7820297691935778\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.36453236762499774   acc max: 0.8876860631334926\n",
      "loss mean : 0.5503390673875647   acc mean: 0.8370906640792896\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3969061578320231   acc max: 0.8863328804182586\n",
      "loss mean : 0.6120715642201238   acc mean: 0.7960622452685407\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4038592340255784   acc max: 0.8728010859315224\n",
      "loss mean : 0.491025853524834   acc mean: 0.8556562944371582\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.43577266997671577   acc max: 0.8728010834311922\n",
      "loss mean : 0.5831769165755609   acc mean: 0.8482138026534948\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4400654492826681   acc max: 0.8755074383764048\n",
      "loss mean : 0.6445102159438986   acc mean: 0.8192557505724879\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.389860447833922   acc max: 0.8714479043454698\n",
      "loss mean : 0.6046287166043934   acc mean: 0.8216508785660437\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4146832551136714   acc max: 0.879566988538502\n",
      "loss mean : 0.5894084175239558   acc mean: 0.8499729366925152\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5248862352519622   acc max: 0.8755074361986979\n",
      "loss mean : 0.6893540789140576   acc mean: 0.8327875507261013\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5284805755976573   acc max: 0.8700947163069522\n",
      "loss mean : 0.7163618306345804   acc mean: 0.8111366706320333\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5808466363179022   acc max: 0.8565629283533367\n",
      "loss mean : 0.845363578255186   acc mean: 0.6980108254401866\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6452241708525785   acc max: 0.8267929624156152\n",
      "loss mean : 0.8457514187399202   acc mean: 0.6595669826538539\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5747219549141653   acc max: 0.8619756482450823\n",
      "loss mean : 0.7914023847638029   acc mean: 0.7551420840971846\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3111732924339413   acc max: 0.9039242228087295\n",
      "loss mean : 0.5700157153066021   acc mean: 0.8064140730418758\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3399547998653536   acc max: 0.8836265218435346\n",
      "loss mean : 0.4960737963240589   acc mean: 0.845818674015499\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.43015752383917366   acc max: 0.8768606244791829\n",
      "loss mean : 0.559655489575153   acc mean: 0.8564817315606206\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.40669870804062713   acc max: 0.8768606206077039\n",
      "loss mean : 0.5127808413260361   acc mean: 0.8577266568768173\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.47722003972901383   acc max: 0.8633288223301445\n",
      "loss mean : 0.643113205018321   acc mean: 0.8271177257873694\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4010289976012884   acc max: 0.8728010864961131\n",
      "loss mean : 0.6236843014961166   acc mean: 0.8108525025110604\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.46126762197853266   acc max: 0.8741542621136357\n",
      "loss mean : 0.6671592477927832   acc mean: 0.8228281477521173\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.45270518932355436   acc max: 0.86874154222189\n",
      "loss mean : 0.6273672242662259   acc mean: 0.827171854146924\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.45642435679738996   acc max: 0.8714478941021817\n",
      "loss mean : 0.7315544637114173   acc mean: 0.7471718539190709\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5140364273313902   acc max: 0.8782138063878587\n",
      "loss mean : 0.7176283912100553   acc mean: 0.7964817319699491\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5349229091881738   acc max: 0.8673883563610795\n",
      "loss mean : 0.7577474732311879   acc mean: 0.7994316633184804\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5749684893229979   acc max: 0.8538565603418827\n",
      "loss mean : 0.8329529806152894   acc mean: 0.7474424891897727\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3656022337357311   acc max: 0.8917456003100043\n",
      "loss mean : 0.4980762213678257   acc mean: 0.8479025697571013\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4176915307328891   acc max: 0.8809201605265131\n",
      "loss mean : 0.5722493662022771   acc mean: 0.8443301764505642\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.39469510724160606   acc max: 0.8836265243438648\n",
      "loss mean : 0.5625921290887063   acc mean: 0.8406089316185498\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.44558075203463254   acc max: 0.8741542620329799\n",
      "loss mean : 0.5376865559727639   acc mean: 0.8395940458685847\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.42678356727179395   acc max: 0.8809201582681504\n",
      "loss mean : 0.6104564405616791   acc mean: 0.8217997283630669\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4007165317445066   acc max: 0.8741542664690495\n",
      "loss mean : 0.5717820786232072   acc mean: 0.8374830828847034\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5756275061825454   acc max: 0.868741546577304\n",
      "loss mean : 0.7272115790376161   acc mean: 0.7787550729894265\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5859930210410339   acc max: 0.8579161046161058\n",
      "loss mean : 0.7168717020935554   acc mean: 0.804113667826288\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5820401657740705   acc max: 0.8633288303957256\n",
      "loss mean : 0.8762608263440965   acc mean: 0.7078619761458509\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4862801223307727   acc max: 0.8714479065231767\n",
      "loss mean : 0.7316365144519748   acc mean: 0.7853721225910968\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5026141322836662   acc max: 0.8592692802336284\n",
      "loss mean : 0.6504618445905845   acc mean: 0.831948579417514\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.607589035218075   acc max: 0.8606224543186906\n",
      "loss mean : 0.9262372239702286   acc mean: 0.6620838967030199\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3594565090291071   acc max: 0.8890392417352803\n",
      "loss mean : 0.5172790918621222   acc mean: 0.8516508814583611\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.41256351363675037   acc max: 0.8795669805535767\n",
      "loss mean : 0.5715890337750618   acc mean: 0.8382814624474078\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4220682434606617   acc max: 0.8849797018164711\n",
      "loss mean : 0.6225703802019238   acc mean: 0.7994451954206693\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.47852443471167827   acc max: 0.8728010845603736\n",
      "loss mean : 0.6818225367901611   acc mean: 0.7617591347512116\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4128176212633414   acc max: 0.8741542708244634\n",
      "loss mean : 0.6170230348954666   acc mean: 0.825926927657992\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.41964238869966447   acc max: 0.8700947163069522\n",
      "loss mean : 0.6094200182690994   acc mean: 0.8285926908488527\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4812148550124549   acc max: 0.86603517856585\n",
      "loss mean : 0.6337706977979901   acc mean: 0.7860351820215482\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4622826929505365   acc max: 0.8660351822760173\n",
      "loss mean : 0.6633813607870163   acc mean: 0.8193910678309743\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5355409586219891   acc max: 0.8646820023030809\n",
      "loss mean : 0.7528694385653096   acc mean: 0.7664140712073595\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.504694509651406   acc max: 0.8579160943728177\n",
      "loss mean : 0.741730958133815   acc mean: 0.7824357237972329\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5640104513045738   acc max: 0.8579161061485662\n",
      "loss mean : 0.8455978308075659   acc mean: 0.7157916096865082\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.667650170271387   acc max: 0.8281461482764259\n",
      "loss mean : 0.8495582280833278   acc mean: 0.7279702293421161\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.34148548896322395   acc max: 0.8917456003100043\n",
      "loss mean : 0.4748110909136933   acc mean: 0.8677672529672253\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.39019164265573264   acc max: 0.8836265232146835\n",
      "loss mean : 0.6812399216058774   acc mean: 0.7745737477975706\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.38793291786688106   acc max: 0.8809201657691409\n",
      "loss mean : 0.5466027839967781   acc mean: 0.8308795677611404\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4210168705983478   acc max: 0.871447905958586\n",
      "loss mean : 0.6070494910070474   acc mean: 0.8072124497574303\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5023922171741119   acc max: 0.8687415385117228\n",
      "loss mean : 0.6846052616592674   acc mean: 0.7956562902620102\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4165608448169228   acc max: 0.8809201582681504\n",
      "loss mean : 0.6023993442640091   acc mean: 0.8346820020788579\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4366740360553597   acc max: 0.8714478962798886\n",
      "loss mean : 0.651630461382124   acc mean: 0.7932476311502663\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4990064417073788   acc max: 0.8700947141292453\n",
      "loss mean : 0.6380100049846711   acc mean: 0.8341677916844419\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.579911250787433   acc max: 0.8552097403148192\n",
      "loss mean : 0.8333998085689478   acc mean: 0.7299188091760156\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5174258128715948   acc max: 0.868741546577304\n",
      "loss mean : 0.7478653109444656   acc mean: 0.7750202960687335\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5457711469014056   acc max: 0.8687415502874712\n",
      "loss mean : 0.7927431134490424   acc mean: 0.7811366712357419\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7433912020897511   acc max: 0.67117726512465\n",
      "loss mean : 0.98722244614274   acc mean: 0.5883085259186238\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2926831029668067   acc max: 0.9012178656051543\n",
      "loss mean : 0.44326660877353274   acc mean: 0.8670771323888485\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.32340212519178535   acc max: 0.8944519616270259\n",
      "loss mean : 0.44466089341975995   acc mean: 0.8645737489061844\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3413125698798726   acc max: 0.8876860631334926\n",
      "loss mean : 0.4489774943192531   acc mean: 0.8666576450506631\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.38483294860758543   acc max: 0.8768606258503316\n",
      "loss mean : 0.49361381805193116   acc mean: 0.8508389733282088\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3926963583542304   acc max: 0.876860620527048\n",
      "loss mean : 0.5998416762906902   acc mean: 0.8309607576475014\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3441409961457827   acc max: 0.8863328905808909\n",
      "loss mean : 0.5150790071451132   acc mean: 0.8628822722405961\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3764029696119977   acc max: 0.8849797084302476\n",
      "loss mean : 0.5587200069479916   acc mean: 0.8361975638437336\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.38817572900181047   acc max: 0.8795669863607951\n",
      "loss mean : 0.5664974766062304   acc mean: 0.832868739783522\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.43826156366661856   acc max: 0.8673883666043675\n",
      "loss mean : 0.6507412708245206   acc mean: 0.812422190372289\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.43188946249520505   acc max: 0.8822733484843749\n",
      "loss mean : 0.605103839374524   acc mean: 0.8414208400112366\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.45981598787604555   acc max: 0.868741546577304\n",
      "loss mean : 0.645744068655658   acc mean: 0.8079431674461078\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5057526824438846   acc max: 0.8741542621136357\n",
      "loss mean : 0.7369235812117507   acc mean: 0.773599458348525\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3161587681273485   acc max: 0.8985115015458351\n",
      "loss mean : 0.45551725038494895   acc mean: 0.8597428956914175\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30890406549218863   acc max: 0.8930987830252383\n",
      "loss mean : 0.43021251853167286   acc mean: 0.8659539923128318\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3237278870381264   acc max: 0.8876860617623439\n",
      "loss mean : 0.4758674888113193   acc mean: 0.852219214540212\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.385145659900002   acc max: 0.8782138005806402\n",
      "loss mean : 0.5098577055093078   acc mean: 0.8540324770807414\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3271829853280471   acc max: 0.8903924143685378\n",
      "loss mean : 0.48915005627480185   acc mean: 0.8671583211567148\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3553959355464001   acc max: 0.8863328781598959\n",
      "loss mean : 0.5245887862244704   acc mean: 0.8411907990645813\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3884765578380941   acc max: 0.8782138085655656\n",
      "loss mean : 0.534772930762684   acc mean: 0.8477401893391341\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3861311002255131   acc max: 0.882273344128961\n",
      "loss mean : 0.5707258183485924   acc mean: 0.8181326093809005\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4315810760480625   acc max: 0.8646820103686621\n",
      "loss mean : 0.6467524796938058   acc mean: 0.823125846341192\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.44710517187725063   acc max: 0.8755074361986979\n",
      "loss mean : 0.6536266521018639   acc mean: 0.800960756674187\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.45664929972611196   acc max: 0.8700947221948265\n",
      "loss mean : 0.6543433913753867   acc mean: 0.8078484446011959\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5070287390877978   acc max: 0.8619756380017942\n",
      "loss mean : 0.7124581086377492   acc mean: 0.7890121787084778\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.3330063408137336   acc max: 0.8930987791537593\n",
      "loss mean : 0.45098731135362213   acc mean: 0.8623139381078002\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.32403729426522054   acc max: 0.8836265204723859\n",
      "loss mean : 0.47753590748419783   acc mean: 0.8625169166245062\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.342349749497051   acc max: 0.8876860603911951\n",
      "loss mean : 0.4641639569571118   acc mean: 0.8698917469854124\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.39875785080925213   acc max: 0.8768606219788527\n",
      "loss mean : 0.5544201536297153   acc mean: 0.8490392426765334\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38414784979594413   acc max: 0.8863328825153098\n",
      "loss mean : 0.525586385709991   acc mean: 0.8526116368985143\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.351202026715298   acc max: 0.8863328803376028\n",
      "loss mean : 0.523068897324502   acc mean: 0.8365493900186718\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.35708828022418715   acc max: 0.8768606285926293\n",
      "loss mean : 0.5458797253166225   acc mean: 0.828078484182348\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4410562362012747   acc max: 0.8700947141292453\n",
      "loss mean : 0.5851179566701146   acc mean: 0.8413261140884986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4385490428369003   acc max: 0.8782138085655656\n",
      "loss mean : 0.6438333474117783   acc mean: 0.7959269287984653\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4900811720281557   acc max: 0.8714478962798886\n",
      "loss mean : 0.7059771135816392   acc mean: 0.7685926918336601\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.44835586384120263   acc max: 0.8768606161716342\n",
      "loss mean : 0.6241180962130568   acc mean: 0.8192557486508634\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.48329042097873715   acc max: 0.8728010740751181\n",
      "loss mean : 0.64131097611055   acc mean: 0.8388092012568318\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.31181231822632   acc max: 0.898511499045505\n",
      "loss mean : 0.45661138768649395   acc mean: 0.8629093371628103\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3232309289568977   acc max: 0.8917456044234506\n",
      "loss mean : 0.4264452133477944   acc mean: 0.8701217857741211\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.317138003601273   acc max: 0.8849797031876199\n",
      "loss mean : 0.44122193948825733   acc mean: 0.8681461428232865\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.38734998637671725   acc max: 0.8782138005806402\n",
      "loss mean : 0.47166456741957596   acc mean: 0.8624357232407078\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38406213021084806   acc max: 0.8795669907162089\n",
      "loss mean : 0.5285022989758297   acc mean: 0.8416238176250004\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3441988551568275   acc max: 0.8809201706891453\n",
      "loss mean : 0.5125073840903656   acc mean: 0.8502571044489237\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3788072334978029   acc max: 0.8863328862254771\n",
      "loss mean : 0.5930208453959477   acc mean: 0.8275101486215413\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.42810938105047636   acc max: 0.8714479043454698\n",
      "loss mean : 0.5983341772626476   acc mean: 0.845196209147028\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.44604179952722117   acc max: 0.8849797106079546\n",
      "loss mean : 0.6948857783359831   acc mean: 0.7879566974000289\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4102784877539649   acc max: 0.8714479043454698\n",
      "loss mean : 0.6265653033790471   acc mean: 0.7990392420772611\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4789108945326489   acc max: 0.8700947243725334\n",
      "loss mean : 0.6657034279908153   acc mean: 0.819255751075377\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4916418822273027   acc max: 0.872801076252825\n",
      "loss mean : 0.6931178014244536   acc mean: 0.8219891744936754\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.332299977903921   acc max: 0.8863328804182586\n",
      "loss mean : 0.4734634599182377   acc mean: 0.8547361290156439\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.321066876225607   acc max: 0.8971583229440475\n",
      "loss mean : 0.4647020397832331   acc mean: 0.8670365363294927\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3556397389897797   acc max: 0.88497970568795\n",
      "loss mean : 0.4813993340420141   acc mean: 0.8662110970904283\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.35119776103106176   acc max: 0.8768606233500015\n",
      "loss mean : 0.47509712307395086   acc mean: 0.8616644104367501\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.34648829577578905   acc max: 0.8930987764921176\n",
      "loss mean : 0.49934186855696533   acc mean: 0.8658727996146084\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.35478907174283336   acc max: 0.8849797003646664\n",
      "loss mean : 0.4947896853230481   acc mean: 0.8541542641421294\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3980358052237592   acc max: 0.8849797003646664\n",
      "loss mean : 0.6129504347992847   acc mean: 0.8209878203700295\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4486438208165124   acc max: 0.8714478962798886\n",
      "loss mean : 0.6167804978245489   acc mean: 0.8420838946216966\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.41863444520107623   acc max: 0.8795669863607951\n",
      "loss mean : 0.6358208400394179   acc mean: 0.8112313935237261\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4318337047293641   acc max: 0.8795669863607951\n",
      "loss mean : 0.6186425557030877   acc mean: 0.8268470901190347\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.47015386239117635   acc max: 0.8660351844537242\n",
      "loss mean : 0.68791609145711   acc mean: 0.8135047367332104\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.46965911141590433   acc max: 0.8714478941021817\n",
      "loss mean : 0.6408146571951725   acc mean: 0.8152097422291851\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.30054459617005636   acc max: 0.8998646790184414\n",
      "loss mean : 0.45553578625270574   acc mean: 0.8693369416834054\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3178654399389182   acc max: 0.8971583229440475\n",
      "loss mean : 0.46018784923909983   acc mean: 0.8653315297305504\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.36635042531403217   acc max: 0.8795669857962044\n",
      "loss mean : 0.49544608236085097   acc mean: 0.848403249276507\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.36721132863035705   acc max: 0.8768606258503316\n",
      "loss mean : 0.49334993093963886   acc mean: 0.859025712707288\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.32968114782250785   acc max: 0.8985115081596117\n",
      "loss mean : 0.5025266724147396   acc mean: 0.8491474944457958\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3474253531802491   acc max: 0.8822733484843749\n",
      "loss mean : 0.5517337612204848   acc mean: 0.8348308518117595\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.42696852419469933   acc max: 0.872801076252825\n",
      "loss mean : 0.5735700569617409   acc mean: 0.8504330159443481\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4124666258833889   acc max: 0.875507442086572\n",
      "loss mean : 0.6255248205115734   acc mean: 0.803775371988184\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.49325014064050654   acc max: 0.8714478941021817\n",
      "loss mean : 0.6846215484937569   acc mean: 0.8141813248162015\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.46430684434544894   acc max: 0.868741534156309\n",
      "loss mean : 0.6971516624484235   acc mean: 0.7850202965881572\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.47092051354409553   acc max: 0.8768606264149224\n",
      "loss mean : 0.665209200445951   acc mean: 0.8205412712467379\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4811835583395177   acc max: 0.8646820103686621\n",
      "loss mean : 0.6701948302701942   acc mean: 0.8257239533293393\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.32146978483148453   acc max: 0.8971583229440475\n",
      "loss mean : 0.4480142375742146   acc mean: 0.8597158320959915\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.33290174986577326   acc max: 0.8849796990741735\n",
      "loss mean : 0.4550271092260481   acc mean: 0.8620974283168379\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3341639179015514   acc max: 0.8876860617623439\n",
      "loss mean : 0.4838017345535416   acc mean: 0.8623139368411006\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.38961472454025875   acc max: 0.8755074458773953\n",
      "loss mean : 0.508263283891752   acc mean: 0.857861977394605\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38564646070639075   acc max: 0.8822733484843749\n",
      "loss mean : 0.542035304094603   acc mean: 0.8469688754217229\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.34432958201561953   acc max: 0.886332888403184\n",
      "loss mean : 0.5050504544712049   acc mean: 0.8598917455005389\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.350305269793664   acc max: 0.8849797084302476\n",
      "loss mean : 0.5130213476840473   acc mean: 0.8475236811592711\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4132735225925265   acc max: 0.8782137983222775\n",
      "loss mean : 0.6703229379645866   acc mean: 0.800054126738776\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.46846497353262123   acc max: 0.8741542562257615\n",
      "loss mean : 0.6767759508801892   acc mean: 0.8191474956076428\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4631388484221834   acc max: 0.8660351844537242\n",
      "loss mean : 0.6875063164534201   acc mean: 0.8132070366447445\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4587470223681046   acc max: 0.8728010821406993\n",
      "loss mean : 0.6386203029070237   acc mean: 0.8277131269854039\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5152397456607896   acc max: 0.872801076252825\n",
      "loss mean : 0.7118680223834691   acc mean: 0.8066441143599512\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.30707351199990196   acc max: 0.8985115042881326\n",
      "loss mean : 0.44338330431300677   acc mean: 0.8644654928532927\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.34411593715134753   acc max: 0.8930987830252383\n",
      "loss mean : 0.5050464561367874   acc mean: 0.8541001349425443\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.32243997132826563   acc max: 0.8863328817894075\n",
      "loss mean : 0.4730943623423092   acc mean: 0.851623816480898\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3809914406242809   acc max: 0.8741542659044589\n",
      "loss mean : 0.5109794547823189   acc mean: 0.8550473627081101\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3465724838280065   acc max: 0.8822733506620818\n",
      "loss mean : 0.5390867526839326   acc mean: 0.8254803774385876\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.37038936481101586   acc max: 0.8768606264149224\n",
      "loss mean : 0.5314201750964209   acc mean: 0.8324627889122147\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.37249328064983045   acc max: 0.8822733382410868\n",
      "loss mean : 0.5446655207255374   acc mean: 0.8355345049516597\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4116461467759051   acc max: 0.8768606242372154\n",
      "loss mean : 0.6169752221283313   acc mean: 0.8377537185961887\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 512   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.46938351905716935   acc max: 0.8755074507973998\n",
      "loss mean : 0.6330558970889156   acc mean: 0.8218267931126775\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4087593540529114   acc max: 0.8768606139939273\n",
      "loss mean : 0.6424355474755632   acc mean: 0.7992557493188949\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.505838331253506   acc max: 0.8673883644266606\n",
      "loss mean : 0.735457154839868   acc mean: 0.8112584576603523\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 8 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.502733538534709   acc max: 0.8646820023030809\n",
      "loss mean : 0.7082705319201996   acc mean: 0.8077672529277039\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.36138854963208406   acc max: 0.8863328804182586\n",
      "loss mean : 0.49820791055489944   acc mean: 0.8542760492476141\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3406622801001243   acc max: 0.8890392431064291\n",
      "loss mean : 0.49626599978287594   acc mean: 0.8468064944278727\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3394496936114134   acc max: 0.8863328817894075\n",
      "loss mean : 0.45952883283082147   acc mean: 0.8681596753594036\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3550513684346324   acc max: 0.8836265204723859\n",
      "loss mean : 0.4655785097042665   acc mean: 0.8636129915198067\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3490364159556945   acc max: 0.8863328781598959\n",
      "loss mean : 0.5209877650974083   acc mean: 0.8621109606609936\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.38048188418593554   acc max: 0.8809201685114384\n",
      "loss mean : 0.5647402129190217   acc mean: 0.8324763199267592\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.36802989708231976   acc max: 0.875507446441986\n",
      "loss mean : 0.54259996344014   acc mean: 0.8458863331690049\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4216061466359641   acc max: 0.8728010843184062\n",
      "loss mean : 0.5555022794605109   acc mean: 0.8531258453454958\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4606922414854512   acc max: 0.8768606264149224\n",
      "loss mean : 0.6170914826664131   acc mean: 0.855913395113003\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4571722364393397   acc max: 0.8768606264149224\n",
      "loss mean : 0.5955352189092417   acc mean: 0.8404465475505034\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.45020251022462754   acc max: 0.8768606264149224\n",
      "loss mean : 0.6445594806325936   acc mean: 0.8268064960494579\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5399811422711942   acc max: 0.8606224704498528\n",
      "loss mean : 0.7550416406476933   acc mean: 0.7627334228996817\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3145576866295728   acc max: 0.8985115015458351\n",
      "loss mean : 0.4670588094282375   acc mean: 0.8595534498556057\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3341097113889351   acc max: 0.88497970568795\n",
      "loss mean : 0.49821981559103   acc mean: 0.8592016260364221\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3258052778018182   acc max: 0.8836265257150137\n",
      "loss mean : 0.48869012240385984   acc mean: 0.8594316669116969\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.36892402736679303   acc max: 0.8795669844250557\n",
      "loss mean : 0.5006959853745765   acc mean: 0.8641407319455735\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38469323152940876   acc max: 0.8890392424611826\n",
      "loss mean : 0.5872237346140877   acc mean: 0.8161975644155831\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3929665670988524   acc max: 0.8836265306350182\n",
      "loss mean : 0.5317398397328083   acc mean: 0.8538294993278458\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3688266056719588   acc max: 0.8795669804729209\n",
      "loss mean : 0.5427630094088947   acc mean: 0.8484032491652017\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4087659623045399   acc max: 0.8741542642913426\n",
      "loss mean : 0.5776615011550901   acc mean: 0.8367929623551233\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.41935797973317934   acc max: 0.875507446441986\n",
      "loss mean : 0.5760999961969655   acc mean: 0.842976996083221\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5084479715730567   acc max: 0.8714479065231767\n",
      "loss mean : 0.7389590773546968   acc mean: 0.7636535867338894\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4935171879192812   acc max: 0.8660351844537242\n",
      "loss mean : 0.7212637609178867   acc mean: 0.7806089308749029\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5204855384297558   acc max: 0.8660351742104361\n",
      "loss mean : 0.7071791659890395   acc mean: 0.8262381583940192\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3211647973412267   acc max: 0.8971583229440475\n",
      "loss mean : 0.43119951478239643   acc mean: 0.8736129910810392\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.31710097109029356   acc max: 0.8917456044234506\n",
      "loss mean : 0.45314920025926797   acc mean: 0.8575101501769882\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3276185650222195   acc max: 0.8809201657691409\n",
      "loss mean : 0.4446266706636697   acc mean: 0.8651150217220812\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3584985769327342   acc max: 0.8741542606618311\n",
      "loss mean : 0.48423117429219653   acc mean: 0.8555480381846431\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3712261999088953   acc max: 0.8809201663337315\n",
      "loss mean : 0.5229704051830771   acc mean: 0.8548579157394874\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3521727138023738   acc max: 0.8890392505267638\n",
      "loss mean : 0.5683917132136947   acc mean: 0.8208525029929791\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 256   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.40911333688379786   acc max: 0.8768606264149224\n",
      "loss mean : 0.5633961469330226   acc mean: 0.8532205651593627\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3919550980540832   acc max: 0.8782138085655656\n",
      "loss mean : 0.5477261443438163   acc mean: 0.8482543971638558\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.46875207390288376   acc max: 0.875507446441986\n",
      "loss mean : 0.6567984371683755   acc mean: 0.8160893083653125\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4407581832154033   acc max: 0.868741544399597\n",
      "loss mean : 0.6774414838594416   acc mean: 0.796576453612283\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5276772577481922   acc max: 0.8646820023030809\n",
      "loss mean : 0.7292463099028972   acc mean: 0.7922192149164714\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5217539695506167   acc max: 0.868741534156309\n",
      "loss mean : 0.7040734631774874   acc mean: 0.8128281452384789\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3217849923002865   acc max: 0.9052774041528147\n",
      "loss mean : 0.4708652452517588   acc mean: 0.8627198918738449\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2921668035009717   acc max: 0.8890392431064291\n",
      "loss mean : 0.44709533617686836   acc mean: 0.8585656305006296\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.36687137591822705   acc max: 0.8836265204723859\n",
      "loss mean : 0.47339730266869795   acc mean: 0.8641948576196928\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3749553856814182   acc max: 0.8809201618976619\n",
      "loss mean : 0.4752314101903623   acc mean: 0.8606765899074256\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4059846609709873   acc max: 0.8836265284573113\n",
      "loss mean : 0.565367121923115   acc mean: 0.846847089456044\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.37160711794970647   acc max: 0.8836265284573113\n",
      "loss mean : 0.5310507159058071   acc mean: 0.8514208405701814\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.34638517594950446   acc max: 0.8836265262796044\n",
      "loss mean : 0.5062698458790458   acc mean: 0.8540460074980301\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4251368130898766   acc max: 0.8782137939668637\n",
      "loss mean : 0.6194310475097458   acc mean: 0.833585927166216\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4291328288544176   acc max: 0.8782138042101518\n",
      "loss mean : 0.7455831311471731   acc mean: 0.7740460069354558\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4042564465567288   acc max: 0.8768606285926293\n",
      "loss mean : 0.5539273337824259   acc mean: 0.8535453316428183\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4752975726885789   acc max: 0.8728010843184062\n",
      "loss mean : 0.6508743914994077   acc mean: 0.8251150184478587\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 16 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.42707522481639587   acc max: 0.8714478941021817\n",
      "loss mean : 0.6291083002767963   acc mean: 0.8224086614773785\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3113050775776374   acc max: 0.8890392403641315\n",
      "loss mean : 0.4168704628379806   acc mean: 0.8693234087585272\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.32263293640539353   acc max: 0.8930987816540895\n",
      "loss mean : 0.4702998889444322   acc mean: 0.8581596742334482\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3604231127544088   acc max: 0.8876860617623439\n",
      "loss mean : 0.47041302185903866   acc mean: 0.8698782122240013\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.38490045171467957   acc max: 0.8768606206077039\n",
      "loss mean : 0.5009336404585064   acc mean: 0.8513531809178191\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.36404091252848325   acc max: 0.8809201685114384\n",
      "loss mean : 0.5144642379896083   acc mean: 0.8558863306368155\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3547526315278065   acc max: 0.8836265284573113\n",
      "loss mean : 0.5564841726906244   acc mean: 0.8412043283046987\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.38063226517224347   acc max: 0.8755074486196929\n",
      "loss mean : 0.5797058654238794   acc mean: 0.8370230030666668\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4216502149550292   acc max: 0.8700947243725334\n",
      "loss mean : 0.5815601131190951   acc mean: 0.8305412715177414\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4085199521181548   acc max: 0.8822733382410868\n",
      "loss mean : 0.6134323679933045   acc mean: 0.8054668476032308\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4556333037932606   acc max: 0.8741542562257615\n",
      "loss mean : 0.6869050680098902   acc mean: 0.8095128541337944\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.44210048400984725   acc max: 0.8728010864961131\n",
      "loss mean : 0.6821213411337146   acc mean: 0.7612178602963887\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5056040862900317   acc max: 0.8633288303957256\n",
      "loss mean : 0.7356257216202873   acc mean: 0.7746820045271648\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3369716759140985   acc max: 0.8944519654985048\n",
      "loss mean : 0.4728731408808003   acc mean: 0.8623680669226569\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3078014857472199   acc max: 0.8930987802829407\n",
      "loss mean : 0.4320450063636564   acc mean: 0.8712449261606625\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3399385842160701   acc max: 0.8863328817894075\n",
      "loss mean : 0.4850747573428128   acc mean: 0.8596346405434838\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.38219927233191403   acc max: 0.8782137992094915\n",
      "loss mean : 0.5109550005689526   acc mean: 0.8564411377987454\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 256   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.4129292681026846   acc max: 0.8836265182140232\n",
      "loss mean : 0.5836436038132611   acc mean: 0.8170230024383582\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.37299418179204885   acc max: 0.8863328803376028\n",
      "loss mean : 0.555776748636256   acc mean: 0.8427063603850438\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.38213830617671085   acc max: 0.8836265284573113\n",
      "loss mean : 0.5773307536754139   acc mean: 0.8159945882229748\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.39816639125750414   acc max: 0.8795669863607951\n",
      "loss mean : 0.5656064873328873   acc mean: 0.8474830852959088\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4306360664645132   acc max: 0.8714478941021817\n",
      "loss mean : 0.718395263908358   acc mean: 0.765994586885298\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.415346011983203   acc max: 0.8809201663337315\n",
      "loss mean : 0.6196191685375567   acc mean: 0.8252638684779771\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4313764516087766   acc max: 0.879566988538502\n",
      "loss mean : 0.6660939989740052   acc mean: 0.8188497976025161\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.48850242694756657   acc max: 0.8782138063878587\n",
      "loss mean : 0.7115599247002633   acc mean: 0.7588768591371859\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3075179591149858   acc max: 0.906630584125751\n",
      "loss mean : 0.43204642439969343   acc mean: 0.8657239520606234\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3080851813533793   acc max: 0.8958051443422599\n",
      "loss mean : 0.49101358974576803   acc mean: 0.8622056843548083\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.34034808671684164   acc max: 0.8795669857962044\n",
      "loss mean : 0.49619513913968905   acc mean: 0.8499323426229382\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3956862999396008   acc max: 0.878213805823268\n",
      "loss mean : 0.5347711718239707   acc mean: 0.8528687434412628\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.39024947335658766   acc max: 0.8822733506620818\n",
      "loss mean : 0.5738639435172082   acc mean: 0.833788906032968\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3523416374387857   acc max: 0.886332888403184\n",
      "loss mean : 0.5137793967523012   acc mean: 0.8307036541160373\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.42975111614222133   acc max: 0.8755074361986979\n",
      "loss mean : 0.5742731362359449   acc mean: 0.8402571038561036\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4381422913848789   acc max: 0.872801076252825\n",
      "loss mean : 0.6016795304090955   acc mean: 0.8387009462879541\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4276866703539966   acc max: 0.875507446441986\n",
      "loss mean : 0.6514802365680508   acc mean: 0.8131393769593136\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4774535386262308   acc max: 0.8673883541833726\n",
      "loss mean : 0.6985054892914545   acc mean: 0.8077537204875677\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.46675996189994967   acc max: 0.8700947243725334\n",
      "loss mean : 0.7259268589400473   acc mean: 0.7751556146935294\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5126771680879657   acc max: 0.8660351822760173\n",
      "loss mean : 0.7075500425829456   acc mean: 0.8032205669454859\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3373635000321152   acc max: 0.8971583202017499\n",
      "loss mean : 0.4705270136705272   acc mean: 0.8696075765302603\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3254996757546039   acc max: 0.8958051429711111\n",
      "loss mean : 0.46860422318617273   acc mean: 0.863288226661566\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.36179379032009834   acc max: 0.8768606206077039\n",
      "loss mean : 0.4893310224776017   acc mean: 0.8606359945284012\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.39194738405160556   acc max: 0.8768606233500015\n",
      "loss mean : 0.5122032609961029   acc mean: 0.860852502533644\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.35173185163647624   acc max: 0.8876860646659531\n",
      "loss mean : 0.5325288133736554   acc mean: 0.833179973120296\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.32776671099565996   acc max: 0.8890392505267638\n",
      "loss mean : 0.49587451603198085   acc mean: 0.8544790269008995\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.35294807388753463   acc max: 0.8876860661984135\n",
      "loss mean : 0.5988837133644398   acc mean: 0.8223139369116744\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.43056846544126376   acc max: 0.872801076252825\n",
      "loss mean : 0.6039316073039871   acc mean: 0.835399186246208\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4720460740252019   acc max: 0.8714479065231767\n",
      "loss mean : 0.7049921000624865   acc mean: 0.7599188080091275\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4618946965153711   acc max: 0.8714479065231767\n",
      "loss mean : 0.6915553700802934   acc mean: 0.7674289581623224\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.475192937057299   acc max: 0.8700947163069522\n",
      "loss mean : 0.6379959952879662   acc mean: 0.8388092004857622\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 16 , 32 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4766000927059189   acc max: 0.8714479043454698\n",
      "loss mean : 0.664825113633489   acc mean: 0.8242895789986858\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.30643028984695714   acc max: 0.8985115056592815\n",
      "loss mean : 0.3966973591492044   acc mean: 0.8810554817024523\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2867232760734584   acc max: 0.8985115042881326\n",
      "loss mean : 0.3794750068156258   acc mean: 0.8736941817366545\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.31847668694223863   acc max: 0.8876860645046415\n",
      "loss mean : 0.4076334579738616   acc mean: 0.8725439785443077\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3330976138740818   acc max: 0.8876860590200463\n",
      "loss mean : 0.46793012510899445   acc mean: 0.8680920170011638\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.31371114436279934   acc max: 0.8958051503914457\n",
      "loss mean : 0.4727177290676895   acc mean: 0.8660622476870055\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3177830672473804   acc max: 0.8971583244765079\n",
      "loss mean : 0.4435491751499363   acc mean: 0.8730717185304998\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3476734919944861   acc max: 0.8903924283219933\n",
      "loss mean : 0.5240775473216227   acc mean: 0.8576048696250811\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.34901856331605874   acc max: 0.8863328803376028\n",
      "loss mean : 0.5206310387042443   acc mean: 0.8523815965660532\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.37282562651072854   acc max: 0.8809201560904435\n",
      "loss mean : 0.5357924680421897   acc mean: 0.8549120404570287\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.38756362918426607   acc max: 0.8822733382410868\n",
      "loss mean : 0.5547104296527793   acc mean: 0.8532340998562491\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.37907492872504   acc max: 0.8849797084302476\n",
      "loss mean : 0.5298595544635362   acc mean: 0.8466576440440786\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4135208992093439   acc max: 0.8782138042101518\n",
      "loss mean : 0.6148747739562808   acc mean: 0.8307171850255278\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.29823138104078734   acc max: 0.9066305788831234\n",
      "loss mean : 0.4005970521003048   acc mean: 0.8769282831592391\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2943367155140243   acc max: 0.9025710455780906\n",
      "loss mean : 0.40844900053433064   acc mean: 0.8743437092004192\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3149937377166361   acc max: 0.8917456016811531\n",
      "loss mean : 0.4165915486212512   acc mean: 0.872151556769953\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.34484273892939493   acc max: 0.8903924217082166\n",
      "loss mean : 0.4354346269784502   acc mean: 0.8748579169884423\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3158872505405436   acc max: 0.8917455943414743\n",
      "loss mean : 0.46248963469420135   acc mean: 0.8628958039467647\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.31655096923062864   acc max: 0.901217856329736\n",
      "loss mean : 0.4653349369098917   acc mean: 0.8579431662249789\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.33613696516931296   acc max: 0.886332888403184\n",
      "loss mean : 0.48715470469167327   acc mean: 0.8611096068486793\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3441399834717401   acc max: 0.8863328905808909\n",
      "loss mean : 0.4943145275680558   acc mean: 0.8594722589668948\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3644535269724339   acc max: 0.8836265284573113\n",
      "loss mean : 0.5563278777233964   acc mean: 0.8526387014972986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.38872637550304967   acc max: 0.8876860705538273\n",
      "loss mean : 0.5786474621791963   acc mean: 0.8490798387145156\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4004642494799158   acc max: 0.8768606161716342\n",
      "loss mean : 0.5745839217510855   acc mean: 0.8442760492681813\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.42849401506583973   acc max: 0.868741544399597\n",
      "loss mean : 0.6098683401680121   acc mean: 0.8498105541714475\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.32421613292055296   acc max: 0.8971583256863451\n",
      "loss mean : 0.409582515364974   acc mean: 0.8716779445234752\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3026740841759074   acc max: 0.8985115029169839\n",
      "loss mean : 0.39914463602641603   acc mean: 0.8735453305813877\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.30459977877962735   acc max: 0.8944519643693235\n",
      "loss mean : 0.4008677808805313   acc mean: 0.8741136672241921\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.32771859919911955   acc max: 0.8836265204723859\n",
      "loss mean : 0.42782066072396563   acc mean: 0.8706089318169634\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.31649425258817143   acc max: 0.8930987904455729\n",
      "loss mean : 0.4620638586780376   acc mean: 0.8560622477200743\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.33151385506693176   acc max: 0.8958051342602834\n",
      "loss mean : 0.4795822769673655   acc mean: 0.8631799718475474\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3308025589250583   acc max: 0.8944519601752213\n",
      "loss mean : 0.5253335672629056   acc mean: 0.8519891747921019\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3542495721973811   acc max: 0.8809201582681504\n",
      "loss mean : 0.4846164166983797   acc mean: 0.858525035192986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3582922204502219   acc max: 0.8822733463066679\n",
      "loss mean : 0.5289365905676546   acc mean: 0.8549391070435752\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.359273726385243   acc max: 0.8809201582681504\n",
      "loss mean : 0.5787611942321909   acc mean: 0.8535994568321961\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.3651450553024251   acc max: 0.8836265182140232\n",
      "loss mean : 0.5476041931922123   acc mean: 0.8395534512271579\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4021074519428413   acc max: 0.8728010864961131\n",
      "loss mean : 0.546651091960754   acc mean: 0.8601623822379658\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.319956337849084   acc max: 0.902571042835793\n",
      "loss mean : 0.4190228523380541   acc mean: 0.8776725296908046\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2904645825997096   acc max: 0.9025710455780906\n",
      "loss mean : 0.41945501894484666   acc mean: 0.8788362671057811\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.32046647496894504   acc max: 0.8917456030523019\n",
      "loss mean : 0.44665865608698935   acc mean: 0.8704600814618019\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.34075484446001636   acc max: 0.8903924230793655\n",
      "loss mean : 0.447350965461647   acc mean: 0.8715832210869522\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.33617506854750306   acc max: 0.8863328825153098\n",
      "loss mean : 0.48260529529903196   acc mean: 0.8544113679808918\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.2870809341880401   acc max: 0.8971583185886337\n",
      "loss mean : 0.44304602536442156   acc mean: 0.8652232737933994\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3089963206983548   acc max: 0.8930987904455729\n",
      "loss mean : 0.46129143297672265   acc mean: 0.8693098786057897\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.37135010465717444   acc max: 0.8768606183493411\n",
      "loss mean : 0.5367205775981827   acc mean: 0.8479025686803463\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.37232240586868   acc max: 0.8849797084302476\n",
      "loss mean : 0.5384833856852516   acc mean: 0.859742893224156\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.36978463278087775   acc max: 0.8809201626235642\n",
      "loss mean : 0.5520457390200785   acc mean: 0.8449391059010858\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.37373774320250114   acc max: 0.879566988538502\n",
      "loss mean : 0.5632325590483552   acc mean: 0.848132610283943\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.40487018473577435   acc max: 0.8741542664690495\n",
      "loss mean : 0.5878374896058373   acc mean: 0.8343301746837988\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2877965098062936   acc max: 0.9093369454427727\n",
      "loss mean : 0.3791469731382492   acc mean: 0.8849526396309085\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2995703973289433   acc max: 0.9012178656051543\n",
      "loss mean : 0.402470465359733   acc mean: 0.8750338305704328\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.28554530657515315   acc max: 0.8917456030523019\n",
      "loss mean : 0.3967144379628688   acc mean: 0.8736265225904074\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.34333694279597154   acc max: 0.8876860603911951\n",
      "loss mean : 0.471533673620595   acc mean: 0.860960758207454\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.32840016722195203   acc max: 0.8890392343956014\n",
      "loss mean : 0.4601798427842951   acc mean: 0.8676184036613962\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3267058944669886   acc max: 0.8876860683761204\n",
      "loss mean : 0.4839875301714679   acc mean: 0.8518673874371268\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3340758521598795   acc max: 0.8876860581328324\n",
      "loss mean : 0.4735965248393915   acc mean: 0.8626792944284186\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3475732743256147   acc max: 0.8903924202564121\n",
      "loss mean : 0.5001961445393032   acc mean: 0.8611366706695384\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.36438183496543614   acc max: 0.8849797003646664\n",
      "loss mean : 0.5141270196341048   acc mean: 0.8571989191973808\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3542367354216853   acc max: 0.8876860705538273\n",
      "loss mean : 0.5347511441273682   acc mean: 0.8474424900733568\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4298171564351883   acc max: 0.868741544399597\n",
      "loss mean : 0.6282073070235924   acc mean: 0.8228010825742241\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.38293107783520175   acc max: 0.8741542584034684\n",
      "loss mean : 0.5754174955804229   acc mean: 0.8528958030369671\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3187707963428575   acc max: 0.9012178642340055\n",
      "loss mean : 0.41667767195885497   acc mean: 0.8754127205361852\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3106213327754334   acc max: 0.8958051443422599\n",
      "loss mean : 0.41829649251675244   acc mean: 0.8748579155334116\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.30661331889432564   acc max: 0.8998646856322179\n",
      "loss mean : 0.40312264906618045   acc mean: 0.8825981057924253\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.32505952049656717   acc max: 0.8876860603911951\n",
      "loss mean : 0.4411479456696523   acc mean: 0.8697022996006057\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.336400970070546   acc max: 0.8917456045847623\n",
      "loss mean : 0.4452592197988128   acc mean: 0.8654262519967572\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.32193323151184516   acc max: 0.8890392505267638\n",
      "loss mean : 0.48364391984168514   acc mean: 0.8640189442445848\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3335060797057068   acc max: 0.8930987743144106\n",
      "loss mean : 0.4629290446159159   acc mean: 0.8666035182816411\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.34215284458516576   acc max: 0.8876860683761204\n",
      "loss mean : 0.46597757976618126   acc mean: 0.860202976366825\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3483896651916478   acc max: 0.8822733382410868\n",
      "loss mean : 0.5514280200169922   acc mean: 0.8329769952917858\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.40700542116197425   acc max: 0.8822733484843749\n",
      "loss mean : 0.6127724884791206   acc mean: 0.8014749650108718\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.39945812319709095   acc max: 0.8809201663337315\n",
      "loss mean : 0.535009312705113   acc mean: 0.8553991874318483\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.41330319618823885   acc max: 0.879566988538502\n",
      "loss mean : 0.6419940415242529   acc mean: 0.8190798387893241\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.29862338671503597   acc max: 0.8985115029169839\n",
      "loss mean : 0.39158406286786474   acc mean: 0.8803924224284733\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.322758730717699   acc max: 0.8985115042881326\n",
      "loss mean : 0.42468476041324726   acc mean: 0.8694857918199894\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3202288416548253   acc max: 0.8890392403641315\n",
      "loss mean : 0.4232606660432519   acc mean: 0.8711366718942964\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.34544678510283905   acc max: 0.8876860590200463\n",
      "loss mean : 0.43795656241809233   acc mean: 0.8740324768048987\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3166974426041759   acc max: 0.8917455943414743\n",
      "loss mean : 0.4788633148208845   acc mean: 0.8566711762769296\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3185928551850687   acc max: 0.8930987802022848\n",
      "loss mean : 0.46739118568589133   acc mean: 0.8565223288253776\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3399480653470521   acc max: 0.8890392424611826\n",
      "loss mean : 0.47551077786858253   acc mean: 0.8558322065935564\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.34500713241116443   acc max: 0.886332888403184\n",
      "loss mean : 0.48244877606025405   acc mean: 0.8675507444796609\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.40078332306406333   acc max: 0.8755074507973998\n",
      "loss mean : 0.5661361302772135   acc mean: 0.8385791615917977\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.34957829888037967   acc max: 0.8782138042101518\n",
      "loss mean : 0.5667941967205362   acc mean: 0.849769958565377\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.36875909042616495   acc max: 0.879566976117507\n",
      "loss mean : 0.521047910109505   acc mean: 0.8613261141739934\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4054522190106899   acc max: 0.875507446441986\n",
      "loss mean : 0.6052599632328676   acc mean: 0.8317591328307966\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.300261030258442   acc max: 0.8998646815187715\n",
      "loss mean : 0.3909532586349041   acc mean: 0.8768876853548949\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30493033073429165   acc max: 0.8985115056592815\n",
      "loss mean : 0.38643431036454573   acc mean: 0.8784844389618331\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3063539939255773   acc max: 0.9025710455780906\n",
      "loss mean : 0.42178017489400377   acc mean: 0.8797293646788888\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3384546185055992   acc max: 0.8890392417352803\n",
      "loss mean : 0.44847491176993015   acc mean: 0.8718132616896105\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.31482103079839713   acc max: 0.8958051445035715\n",
      "loss mean : 0.464405646227774   acc mean: 0.860595398271842\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3217166404924148   acc max: 0.8917456104726366\n",
      "loss mean : 0.4595842519987259   acc mean: 0.8668606232790245\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3390443075816267   acc max: 0.8863328905808909\n",
      "loss mean : 0.49155340533577546   acc mean: 0.8566576461028181\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3408265820375476   acc max: 0.8836265284573113\n",
      "loss mean : 0.5236245141227771   acc mean: 0.8539512851233413\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3642317838613977   acc max: 0.8849797084302476\n",
      "loss mean : 0.5317741536444838   acc mean: 0.8501217870008962\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.39987962167705027   acc max: 0.8768606183493411\n",
      "loss mean : 0.5619498984037782   acc mean: 0.8465629211173006\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.39278359265546836   acc max: 0.8822733463066679\n",
      "loss mean : 0.5740825292488235   acc mean: 0.8488497958978557\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 8 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4192882845221095   acc max: 0.8741542562257615\n",
      "loss mean : 0.5964236704499054   acc mean: 0.8335317986288154\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3059265967231642   acc max: 0.8998646856322179\n",
      "loss mean : 0.387354212703337   acc mean: 0.8830987834438421\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30755706806950706   acc max: 0.9012178656051543\n",
      "loss mean : 0.4017693948318252   acc mean: 0.8790798381273417\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.30110269059025063   acc max: 0.8958051443422599\n",
      "loss mean : 0.39728027390852994   acc mean: 0.8769418138031707\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.31596316927502055   acc max: 0.8890392403641315\n",
      "loss mean : 0.4279910372437578   acc mean: 0.8730175921236225\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.32956177020427824   acc max: 0.8917456045847623\n",
      "loss mean : 0.4707036928584515   acc mean: 0.8601082536138606\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3164103807067355   acc max: 0.8876860603105393\n",
      "loss mean : 0.45541031947598887   acc mean: 0.8585656289762348\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3398232272093932   acc max: 0.886332888403184\n",
      "loss mean : 0.49583128313532704   acc mean: 0.8564276041269949\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.32865070760330745   acc max: 0.8863328862254771\n",
      "loss mean : 0.486920188871869   acc mean: 0.8644925550670841\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 512   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.39628492604250515   acc max: 0.8809201582681504\n",
      "loss mean : 0.5614886495285493   acc mean: 0.843477672526817\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3991072850153153   acc max: 0.8795669782952139\n",
      "loss mean : 0.5619284029198113   acc mean: 0.8504600814045363\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.3918589282181008   acc max: 0.8809201582681504\n",
      "loss mean : 0.5778733605598081   acc mean: 0.8499864676260015\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4085697723257687   acc max: 0.879566988538502\n",
      "loss mean : 0.59750866119247   acc mean: 0.820581866914913\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3296478972222066   acc max: 0.8903924244505143\n",
      "loss mean : 0.4172243550637578   acc mean: 0.8739512859984567\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3052541825703581   acc max: 0.9025710455780906\n",
      "loss mean : 0.3817167955128847   acc mean: 0.8793504738396333\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.30183712353725717   acc max: 0.8917456016811531\n",
      "loss mean : 0.4126536558905216   acc mean: 0.8717726665719112\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3536895980128416   acc max: 0.8863328817894075\n",
      "loss mean : 0.4676537552205732   acc mean: 0.866238158454108\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3191981715262339   acc max: 0.890392422434119\n",
      "loss mean : 0.4517707060182691   acc mean: 0.8697834914495237\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3116317178060947   acc max: 0.8930987904455729\n",
      "loss mean : 0.4495180403795069   acc mean: 0.8611502024979003\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3214824270653628   acc max: 0.8944519645306351\n",
      "loss mean : 0.457048423468502   acc mean: 0.8691204330877618\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.34869678784287833   acc max: 0.8809201663337315\n",
      "loss mean : 0.532878622513098   acc mean: 0.8488903908659382\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3664787839568839   acc max: 0.8809201604458573\n",
      "loss mean : 0.5434451228811712   acc mean: 0.8384167789767655\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3831960645193015   acc max: 0.8809201582681504\n",
      "loss mean : 0.5743537718581895   acc mean: 0.8418132601208552\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4135012354837864   acc max: 0.8782137961445706\n",
      "loss mean : 0.58866372396804   acc mean: 0.834627871607734\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.41774333479117315   acc max: 0.8755074361986979\n",
      "loss mean : 0.6010924714287499   acc mean: 0.8357374833102803\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3081462586926188   acc max: 0.8958051402288135\n",
      "loss mean : 0.39633428654546504   acc mean: 0.870054127283606\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3116414424772998   acc max: 0.8998646842610691\n",
      "loss mean : 0.39794674351589615   acc mean: 0.8761975652624693\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.321521161010688   acc max: 0.8890392417352803\n",
      "loss mean : 0.43896805963271035   acc mean: 0.8687686067371954\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.342647911852203   acc max: 0.8849797004453223\n",
      "loss mean : 0.45044984241582064   acc mean: 0.8685791612776432\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.29140550563558026   acc max: 0.8944519645306351\n",
      "loss mean : 0.4426948171777396   acc mean: 0.8643843027259724\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.2901523213667218   acc max: 0.8958051423258646\n",
      "loss mean : 0.4422811346016169   acc mean: 0.8670500692640494\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3292343261600025   acc max: 0.8863328825153098\n",
      "loss mean : 0.46267107673886654   acc mean: 0.8663058200692291\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.33259599445153315   acc max: 0.8809201582681504\n",
      "loss mean : 0.4978599212884258   acc mean: 0.8595128554775203\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3610876585698418   acc max: 0.8863328781598959\n",
      "loss mean : 0.538478840758094   acc mean: 0.8388903904509638\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3708244798873855   acc max: 0.8849797084302476\n",
      "loss mean : 0.5343883534108511   acc mean: 0.8628281460345518\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.3702337362769492   acc max: 0.8809201663337315\n",
      "loss mean : 0.5521234593944717   acc mean: 0.8529228660758682\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4201638053734667   acc max: 0.8741542642913426\n",
      "loss mean : 0.6128284282496399   acc mean: 0.8316644084885092\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.29845660412747094   acc max: 0.9039242241798783\n",
      "loss mean : 0.3837766263808385   acc mean: 0.885832206641547\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2915667701557944   acc max: 0.8944519629981746\n",
      "loss mean : 0.3948991302631705   acc mean: 0.8712313945698318\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.2991456214404074   acc max: 0.8930987816540895\n",
      "loss mean : 0.41499922345754103   acc mean: 0.869891745577162\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.34500599972127416   acc max: 0.8849797004453223\n",
      "loss mean : 0.4657357652402698   acc mean: 0.8584709068693231\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3361258295859955   acc max: 0.8836265306350182\n",
      "loss mean : 0.46574644077171   acc mean: 0.8669959421861154\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3325288021919369   acc max: 0.8876860705538273\n",
      "loss mean : 0.4755155304255762   acc mean: 0.8599188089257807\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 256   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.33049480381128105   acc max: 0.8890392483490568\n",
      "loss mean : 0.4771635949531008   acc mean: 0.8574289575146564\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.33108399822521595   acc max: 0.8782137983222775\n",
      "loss mean : 0.47443713469619836   acc mean: 0.8597970230274499\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3783422732304817   acc max: 0.8849797106079546\n",
      "loss mean : 0.5229574495924987   acc mean: 0.8636535851994127\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3838969142011118   acc max: 0.8809201706891453\n",
      "loss mean : 0.6039169136084949   acc mean: 0.8235047374095097\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.3851456364291608   acc max: 0.8782137961445706\n",
      "loss mean : 0.6065430336492955   acc mean: 0.8367658977652113\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 16 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.38981534570899157   acc max: 0.8714478962798886\n",
      "loss mean : 0.5553090394414326   acc mean: 0.8477266568292299\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2972840960358089   acc max: 0.8985115029169839\n",
      "loss mean : 0.38081162420758047   acc mean: 0.8800000006484727\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30991008111524   acc max: 0.8944519629981746\n",
      "loss mean : 0.401019336222715   acc mean: 0.8809742896055175\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.32418417704766755   acc max: 0.8958051443422599\n",
      "loss mean : 0.4175935800815144   acc mean: 0.8768200278443478\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3342086813527289   acc max: 0.8836265218435346\n",
      "loss mean : 0.4593447462934119   acc mean: 0.8662381589106196\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.31281149508343337   acc max: 0.8903924143685378\n",
      "loss mean : 0.44180498583592653   acc mean: 0.8691610275323883\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3180213573417741   acc max: 0.8985114963838632\n",
      "loss mean : 0.44401061876176656   acc mean: 0.8694993223751993\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3009616391826547   acc max: 0.890392422434119\n",
      "loss mean : 0.4654036119681089   acc mean: 0.8691474965226827\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.34043956960328375   acc max: 0.8849796981869595\n",
      "loss mean : 0.47733806079835794   acc mean: 0.8669959389534309\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.347141353058073   acc max: 0.8863328825153098\n",
      "loss mean : 0.5404142331097058   acc mean: 0.8592828154959115\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3465069135971095   acc max: 0.8809201685114384\n",
      "loss mean : 0.5646694426450259   acc mean: 0.8329905279148092\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.40626563045104236   acc max: 0.8755074361986979\n",
      "loss mean : 0.6042700715949798   acc mean: 0.8334641406863565\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.41658835163458435   acc max: 0.879566988538502\n",
      "loss mean : 0.5933683577264598   acc mean: 0.8435994587594666\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3292738938847801   acc max: 0.8958051443422599\n",
      "loss mean : 0.4036835892089165   acc mean: 0.8769959406092944\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3110255283254409   acc max: 0.8971583229440475\n",
      "loss mean : 0.40247012280845174   acc mean: 0.8713396483800893\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.2907440323629624   acc max: 0.8971583243151963\n",
      "loss mean : 0.40634090151854557   acc mean: 0.8755751015288259\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3271740446313308   acc max: 0.8849797018164711\n",
      "loss mean : 0.42856321317013935   acc mean: 0.8686197566566676\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.34502836827980166   acc max: 0.8944519564650539\n",
      "loss mean : 0.46500129774394305   acc mean: 0.8723545328439972\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3250442665871812   acc max: 0.8930987743144106\n",
      "loss mean : 0.48954107820261794   acc mean: 0.8442895809164793\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3217390324007997   acc max: 0.8917455943414743\n",
      "loss mean : 0.4611328404516749   acc mean: 0.8627334224459926\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3862310276141186   acc max: 0.8768606183493411\n",
      "loss mean : 0.5033399057335878   acc mean: 0.8615967515203724\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3939658101743871   acc max: 0.875507446441986\n",
      "loss mean : 0.5809838436295924   acc mean: 0.8375236807305856\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3723228627031969   acc max: 0.8809201582681504\n",
      "loss mean : 0.5537886285672975   acc mean: 0.8367117733452898\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.39316806471396204   acc max: 0.8782138063878587\n",
      "loss mean : 0.5663527869101467   acc mean: 0.8380649512510178\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.45033497061877836   acc max: 0.872801076252825\n",
      "loss mean : 0.6098120423800567   acc mean: 0.8534235440700724\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3007561966111437   acc max: 0.9012178614917079\n",
      "loss mean : 0.3807103019033297   acc mean: 0.8817320708460673\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2937603066593449   acc max: 0.8998646828899203\n",
      "loss mean : 0.39373113326839254   acc mean: 0.8720433007549689\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.31067546076961716   acc max: 0.8944519629981746\n",
      "loss mean : 0.4168966760122405   acc mean: 0.8716373485028339\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3465855465206306   acc max: 0.8849797004453223\n",
      "loss mean : 0.45589633490058495   acc mean: 0.8706089297707251\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 256   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.31830231440083423   acc max: 0.8958051445035715\n",
      "loss mean : 0.45445206915856373   acc mean: 0.871596752944754\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.2905778312231433   acc max: 0.8930987904455729\n",
      "loss mean : 0.41714815765538615   acc mean: 0.8682814625579063\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.33422323351622596   acc max: 0.8890392402834757\n",
      "loss mean : 0.47849020190910013   acc mean: 0.8585250340859849\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.3726547991551953   acc max: 0.8809201582681504\n",
      "loss mean : 0.5145632703999543   acc mean: 0.8654397835468569\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.36863128080742286   acc max: 0.8822733404187937\n",
      "loss mean : 0.5423628906593109   acc mean: 0.8406765903389342\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.33468812800873277   acc max: 0.8863328781598959\n",
      "loss mean : 0.5236728310726171   acc mean: 0.8304059531018438\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.37957720053212085   acc max: 0.8849796981869595\n",
      "loss mean : 0.5398800045167157   acc mean: 0.8557239501571462\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4368445406263349   acc max: 0.8768606242372154\n",
      "loss mean : 0.6011743030976378   acc mean: 0.8500676582348361\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3008347798506849   acc max: 0.9052774055239635\n",
      "loss mean : 0.38727117712325915   acc mean: 0.8803653596759005\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30788619257761757   acc max: 0.8930987843963871\n",
      "loss mean : 0.4163461094340549   acc mean: 0.8709336952814714\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.28426833658482936   acc max: 0.8930987830252383\n",
      "loss mean : 0.3870765253175578   acc mean: 0.8780514211115882\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.33042948692028834   acc max: 0.8890392444775779\n",
      "loss mean : 0.4548614864089653   acc mean: 0.8674154272856986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3316471301251077   acc max: 0.8863328825153098\n",
      "loss mean : 0.513689558575376   acc mean: 0.8474560226409296\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.2937034291085435   acc max: 0.8930987743144106\n",
      "loss mean : 0.44452385146901796   acc mean: 0.8686468195891024\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.34449633649463424   acc max: 0.8876860624882462\n",
      "loss mean : 0.5066466958000146   acc mean: 0.853382949114491\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.33288268823584943   acc max: 0.8863328905808909\n",
      "loss mean : 0.48733613694835254   acc mean: 0.8524627887843748\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.39269328944092674   acc max: 0.8876860603105393\n",
      "loss mean : 0.5663009069313538   acc mean: 0.8445872801397101\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3525294275987132   acc max: 0.8836265284573113\n",
      "loss mean : 0.5244065243163031   acc mean: 0.8452909332973548\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.41045675814877663   acc max: 0.875507444264279\n",
      "loss mean : 0.5729127309883723   acc mean: 0.8394722590209345\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 1   Node:[ 32 , 32 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4217093957131867   acc max: 0.8714478962798886\n",
      "loss mean : 0.6006078891458144   acc mean: 0.8261028402636436\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.36103776903855783   acc max: 0.8876860631334926\n",
      "loss mean : 0.5709290045023933   acc mean: 0.8099188092947813\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.41354963360845803   acc max: 0.8782137992094915\n",
      "loss mean : 0.5425539829318837   acc mean: 0.8432746936689369\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.6101554425708012   acc max: 0.860622464803946\n",
      "loss mean : 0.8079166617558031   acc mean: 0.7196346416153991\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.7674893252904424   acc max: 0.6589986469813387\n",
      "loss mean : 0.8533910703925222   acc mean: 0.61477672475036\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38717011052797545   acc max: 0.8822733463066679\n",
      "loss mean : 0.600878226796571   acc mean: 0.8275507446913822\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.57462876091468   acc max: 0.8660351742104361\n",
      "loss mean : 0.7970728825796924   acc mean: 0.7318809203115948\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.6932909746776575   acc max: 0.7902571127443739\n",
      "loss mean : 0.8368423449065593   acc mean: 0.6289174547339808\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6536913793206376   acc max: 0.860622468272146\n",
      "loss mean : 0.8309525527110442   acc mean: 0.7507713116610647\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5038108413532396   acc max: 0.8700947302604076\n",
      "loss mean : 0.7584390548416018   acc mean: 0.7720838975531322\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6702934184158283   acc max: 0.6657645554761925\n",
      "loss mean : 0.8961700719796595   acc mean: 0.6165087966207562\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.8055963733199485   acc max: 0.6576454691054534\n",
      "loss mean : 1.0059552456618   acc mean: 0.5111637353864833\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.864689394569526   acc max: 0.635994589538471\n",
      "loss mean : 0.9719027641338972   acc mean: 0.5941136686634954\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.5042965836792741   acc max: 0.8673883660397769\n",
      "loss mean : 0.6475703935738507   acc mean: 0.8057104193607753\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.36157559469362394   acc max: 0.8822733418705982\n",
      "loss mean : 0.598893394156867   acc mean: 0.7737212447832178\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.618772945642794   acc max: 0.8660351794530639\n",
      "loss mean : 0.7577704019814285   acc mean: 0.7633694188226218\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.7914824919707075   acc max: 0.6603518244539449\n",
      "loss mean : 0.8643182011749166   acc mean: 0.6335047341502084\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.49347102242813057   acc max: 0.8782138107432725\n",
      "loss mean : 0.692393578678894   acc mean: 0.8106224608364867\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.6481484100525047   acc max: 0.8227334187866386\n",
      "loss mean : 0.8557441905935335   acc mean: 0.6386468205561657\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.7185069773452046   acc max: 0.6684709132443584\n",
      "loss mean : 0.8118599871797069   acc mean: 0.6408795671489629\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.863377819445201   acc max: 0.6441136737315032\n",
      "loss mean : 0.9926538600739347   acc mean: 0.5520974299021278\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6997997372818251   acc max: 0.7023004051474337\n",
      "loss mean : 0.9119613534042736   acc mean: 0.5871447904682208\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.7267617566337121   acc max: 0.6576454588621653\n",
      "loss mean : 0.8620493500344   acc mean: 0.6459133993308988\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.711201570837359   acc max: 0.6644113630822611\n",
      "loss mean : 0.8141241729856344   acc mean: 0.6234100149912666\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.9112407552211953   acc max: 0.6305818674690185\n",
      "loss mean : 1.0198528140993015   acc mean: 0.560081191604531\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.41221189127884633   acc max: 0.8863328804182586\n",
      "loss mean : 0.6344496282410879   acc mean: 0.7879566974879441\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.42752649380002516   acc max: 0.87415426453331\n",
      "loss mean : 0.5470659245096944   acc mean: 0.8363058198700096\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5271366640259997   acc max: 0.8687415460127133\n",
      "loss mean : 0.6519749668583336   acc mean: 0.8410554809217038\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.7898636303025428   acc max: 0.6576454656372535\n",
      "loss mean : 0.8882260989021706   acc mean: 0.6099323406521134\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4178928487275063   acc max: 0.868741546577304\n",
      "loss mean : 0.7207489070026091   acc mean: 0.7445466840253064\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4041389796343482   acc max: 0.8673883666043675\n",
      "loss mean : 0.6469834565059742   acc mean: 0.768213801916704\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.597102857490999   acc max: 0.8700947163069522\n",
      "loss mean : 0.8017174793185013   acc mean: 0.7302571044759436\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.7799448048310287   acc max: 0.6562922854223496\n",
      "loss mean : 0.8901546793635707   acc mean: 0.6239648165214047\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5818602529043112   acc max: 0.8606224645619786\n",
      "loss mean : 0.8504342278947042   acc mean: 0.6647631936886315\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5577967229812167   acc max: 0.8525033803689464\n",
      "loss mean : 0.7467734930149114   acc mean: 0.7499323410396646\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7282318829360931   acc max: 0.6549391113372875\n",
      "loss mean : 0.9013620733900224   acc mean: 0.6368335569550124\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.8099549561940608   acc max: 0.6359945851830572\n",
      "loss mean : 0.9265075687166803   acc mean: 0.5917050071469986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3200469415871797   acc max: 0.8849797031876199\n",
      "loss mean : 0.5342784885285833   acc mean: 0.8305953985355865\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4428856005849309   acc max: 0.8741542634041287\n",
      "loss mean : 0.6374333385371065   acc mean: 0.788240865996468\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5720410306656958   acc max: 0.8430311265269216\n",
      "loss mean : 0.7358033953177591   acc mean: 0.756806495175955\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6733010253177122   acc max: 0.8673883635394467\n",
      "loss mean : 0.7625922999999842   acc mean: 0.8148443839861349\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5077957406498905   acc max: 0.8565629165775882\n",
      "loss mean : 0.7745535741812968   acc mean: 0.7088362655329931\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.47865450595970566   acc max: 0.8660351742104361\n",
      "loss mean : 0.6447761867535132   acc mean: 0.8291610265770205\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5265886242399358   acc max: 0.860622468272146\n",
      "loss mean : 0.7344907904913366   acc mean: 0.7408660335877105\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.8058460854871025   acc max: 0.6495263914455419\n",
      "loss mean : 0.9038593587404335   acc mean: 0.6125169139398774\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5395001581944374   acc max: 0.872801078430532\n",
      "loss mean : 0.7750643617729372   acc mean: 0.7330717187587561\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.573720178036309   acc max: 0.8619756401795011\n",
      "loss mean : 0.7986899804222084   acc mean: 0.7794993236810168\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.8109480549098674   acc max: 0.6549391032717063\n",
      "loss mean : 0.9095081185649309   acc mean: 0.6289851140028248\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.8736758439402135   acc max: 0.6089309835466222\n",
      "loss mean : 0.9916811588346073   acc mean: 0.5048037895310231\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.3267295754568825   acc max: 0.8863328856608864\n",
      "loss mean : 0.5466334782014518   acc mean: 0.8389309880560887\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4308864961457672   acc max: 0.8795669805535767\n",
      "loss mean : 0.5946620534293868   acc mean: 0.8300811896409652\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.5299405869756887   acc max: 0.8728010793177459\n",
      "loss mean : 0.652366327313109   acc mean: 0.8065087943813475\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6163767884322852   acc max: 0.8646820022224251\n",
      "loss mean : 0.791224393573601   acc mean: 0.7213937741005855\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4117812971623567   acc max: 0.8646820081909551\n",
      "loss mean : 0.641425866575783   acc mean: 0.8063870101146832\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.5307665330953947   acc max: 0.8741542584034684\n",
      "loss mean : 0.7092177614815663   acc mean: 0.7404871458315236\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5668162589789405   acc max: 0.8389715784618754\n",
      "loss mean : 0.7363603031070695   acc mean: 0.7121515558549129\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6269849849327975   acc max: 0.8552097505581072\n",
      "loss mean : 0.836226867573671   acc mean: 0.7794722593362985\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5784123287471932   acc max: 0.8538565625195896\n",
      "loss mean : 0.8330604624030393   acc mean: 0.7071853859006793\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.49803122922435344   acc max: 0.8673883541833726\n",
      "loss mean : 0.762222190024243   acc mean: 0.7663058181641389\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6673027439917537   acc max: 0.8497970284886547\n",
      "loss mean : 0.9312890411092721   acc mean: 0.6012449260973479\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7382033159187585   acc max: 0.8064952562884484\n",
      "loss mean : 0.9436156453492677   acc mean: 0.5930852506619264\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.32495549119535094   acc max: 0.8944519654985048\n",
      "loss mean : 0.4816327489729018   acc mean: 0.8420162393872566\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.40380046174877876   acc max: 0.8809201605265131\n",
      "loss mean : 0.5412604423232266   acc mean: 0.8250067659789073\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.6777802642853238   acc max: 0.6617050096695091\n",
      "loss mean : 0.7718744158244745   acc mean: 0.6408525037108158\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5697375342391018   acc max: 0.8592692795883818\n",
      "loss mean : 0.710440718266251   acc mean: 0.7859269272781032\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.37350547866182493   acc max: 0.8714478941021817\n",
      "loss mean : 0.6458882472939357   acc mean: 0.8101488501127905\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4295590611046157   acc max: 0.8646820103686621\n",
      "loss mean : 0.6540021927382531   acc mean: 0.8179296339179247\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5012663975458829   acc max: 0.8619756504227892\n",
      "loss mean : 0.7143041257743742   acc mean: 0.7850879569708575\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6259275531252602   acc max: 0.8633288303957256\n",
      "loss mean : 0.802796312680264   acc mean: 0.7351150216091633\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5616561505081528   acc max: 0.861975644534915\n",
      "loss mean : 0.8064311581317724   acc mean: 0.7276725295738536\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.7361530137320171   acc max: 0.6887686032403628\n",
      "loss mean : 0.9643796405385733   acc mean: 0.6087280130100026\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5932004914716068   acc max: 0.8592692867667491\n",
      "loss mean : 0.8096759206572792   acc mean: 0.7276725305453526\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7926566918583459   acc max: 0.6752368072211662\n",
      "loss mean : 0.8947304465435194   acc mean: 0.6508119090911662\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.34366031218930093   acc max: 0.8930987816540895\n",
      "loss mean : 0.535733496377368   acc mean: 0.8372259810679819\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3824779833282605   acc max: 0.8795669819247255\n",
      "loss mean : 0.47684694493454116   acc mean: 0.8649120427379748\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.6420343470670212   acc max: 0.6806495279194699\n",
      "loss mean : 0.7406582119903643   acc mean: 0.6515696899034336\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.554808461900009   acc max: 0.8579161023577431\n",
      "loss mean : 0.6965668523662468   acc mean: 0.8102300395484866\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.4235109732018756   acc max: 0.8646820044807878\n",
      "loss mean : 0.6311144396815959   acc mean: 0.8128416776245757\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.47562564129113183   acc max: 0.8619756460673754\n",
      "loss mean : 0.6863309468048675   acc mean: 0.7761299049942998\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.47346008945059875   acc max: 0.868741544399597\n",
      "loss mean : 0.6533376697161524   acc mean: 0.7956833550616272\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6153483806992094   acc max: 0.8416779405854552\n",
      "loss mean : 0.7905385823324019   acc mean: 0.7516373472010494\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.6058217252381599   acc max: 0.8565629261756298\n",
      "loss mean : 0.8056950664923543   acc mean: 0.6591610283179762\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.6267735851633693   acc max: 0.8619756401795011\n",
      "loss mean : 0.8724783160108998   acc mean: 0.7342760498549521\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.6233754830689489   acc max: 0.8660351903415985\n",
      "loss mean : 0.8173754800817804   acc mean: 0.6816644121369749\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7486038429004737   acc max: 0.6617050133796765\n",
      "loss mean : 0.8683573758037553   acc mean: 0.6226522352924526\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.36050088391091084   acc max: 0.8836265191012371\n",
      "loss mean : 0.5330495739418696   acc mean: 0.8425845747710244\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.4204435663471687   acc max: 0.8741542592906822\n",
      "loss mean : 0.6146462673376313   acc mean: 0.8239783487022327\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4531584541352418   acc max: 0.8728010859315224\n",
      "loss mean : 0.5697570213207696   acc mean: 0.8334235465720156\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5677939200110945   acc max: 0.8741542620329799\n",
      "loss mean : 0.7734626236884616   acc mean: 0.7537077128334686\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.46505294302642264   acc max: 0.8714479087008836\n",
      "loss mean : 0.7143474240421601   acc mean: 0.7613396487325549\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.41194532563625075   acc max: 0.872801076252825\n",
      "loss mean : 0.6132260050470354   acc mean: 0.8036806483342942\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.506607472412641   acc max: 0.8538565684074639\n",
      "loss mean : 0.6916498391892817   acc mean: 0.7817050080029585\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6854520757885522   acc max: 0.8484438485157183\n",
      "loss mean : 0.801576502001334   acc mean: 0.789526387358712\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4875545004062627   acc max: 0.8660351903415985\n",
      "loss mean : 0.7616711699220583   acc mean: 0.7414073085671995\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.48405342656962763   acc max: 0.870094720662366\n",
      "loss mean : 0.6480497065658338   acc mean: 0.8245466821764738\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7909482031133082   acc max: 0.660351823163452\n",
      "loss mean : 0.9423346545409124   acc mean: 0.610270634703691\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 8 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7845444318728776   acc max: 0.6305818652913115\n",
      "loss mean : 0.9284771305572679   acc mean: 0.5607442491367479\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.29833303317326815   acc max: 0.8876860590200463\n",
      "loss mean : 0.5972919729162457   acc mean: 0.7677807839386196\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.34313666284164973   acc max: 0.8836265218435346\n",
      "loss mean : 0.4799688845747863   acc mean: 0.8515561566619816\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4188152095542386   acc max: 0.8728010793177459\n",
      "loss mean : 0.550165932750347   acc mean: 0.8285250349425496\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5228712469218387   acc max: 0.8538565610677851\n",
      "loss mean : 0.6761404577397687   acc mean: 0.7806224626480162\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3376704774625569   acc max: 0.8876860640207066\n",
      "loss mean : 0.5233742073714652   acc mean: 0.8249391066858669\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4344880855131859   acc max: 0.8741542664690495\n",
      "loss mean : 0.6216634028109549   acc mean: 0.8303518260380252\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4686316217072762   acc max: 0.8700947302604076\n",
      "loss mean : 0.6081145870548463   acc mean: 0.8408389734729862\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6735743009995705   acc max: 0.8552097505581072\n",
      "loss mean : 0.8326060695246528   acc mean: 0.6801894474469115\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.42054991853575907   acc max: 0.8728010740751181\n",
      "loss mean : 0.6811723982690958   acc mean: 0.7787686058241718\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4570484604177359   acc max: 0.8673883622489537\n",
      "loss mean : 0.6752148927459859   acc mean: 0.781745602481259\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5162164451950135   acc max: 0.8619756342916269\n",
      "loss mean : 0.75251718267375   acc mean: 0.7956021654626029\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6926226134390566   acc max: 0.8416779442956225\n",
      "loss mean : 0.9089040097130492   acc mean: 0.7057780774524474\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2856792128457107   acc max: 0.8863328804182586\n",
      "loss mean : 0.46028440556482636   acc mean: 0.8448985111995708\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3684720047352601   acc max: 0.8849796990741735\n",
      "loss mean : 0.5228824041717267   acc mean: 0.8433288239222904\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4624182059251891   acc max: 0.8809201591553643\n",
      "loss mean : 0.5901885547205624   acc mean: 0.8120162386266725\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.685598789919697   acc max: 0.6630581843998177\n",
      "loss mean : 0.7613297931089774   acc mean: 0.6301082521975444\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3621915135235199   acc max: 0.879566988538502\n",
      "loss mean : 0.5408459258039201   acc mean: 0.8291474971953522\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.39203837304218536   acc max: 0.8728010902062805\n",
      "loss mean : 0.5674683548374976   acc mean: 0.8359675240169839\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.43938763764294947   acc max: 0.875507442086572\n",
      "loss mean : 0.6174136269947512   acc mean: 0.8291880920912482\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6647986333328267   acc max: 0.7009472186413767\n",
      "loss mean : 0.7834804159047961   acc mean: 0.6500135309359056\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.4679514396335824   acc max: 0.8741542664690495\n",
      "loss mean : 0.6932424231472454   acc mean: 0.7600405954516143\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4882173565630984   acc max: 0.8592692904769165\n",
      "loss mean : 0.7337281572455805   acc mean: 0.7330175921058785\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6456565328638028   acc max: 0.7604871446289455\n",
      "loss mean : 0.8201045013030585   acc mean: 0.6566441137760031\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7492486733706297   acc max: 0.6671177273835478\n",
      "loss mean : 0.8845649895697066   acc mean: 0.6497834920746064\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3559826272911567   acc max: 0.8944519629981746\n",
      "loss mean : 0.5225893860692422   acc mean: 0.8357239517234819\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3634113816592303   acc max: 0.8849796990741735\n",
      "loss mean : 0.5241388359835247   acc mean: 0.8428010811478265\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.41179954808039015   acc max: 0.8728010806888947\n",
      "loss mean : 0.5398397127483469   acc mean: 0.8254397823914625\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5243736565193723   acc max: 0.8768606206077039\n",
      "loss mean : 0.6535201486364431   acc mean: 0.8179431651897616\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.34039268030687986   acc max: 0.8836265306350182\n",
      "loss mean : 0.551810593184018   acc mean: 0.8156292298145803\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.40253319408800026   acc max: 0.8836265262796044\n",
      "loss mean : 0.5578038822947239   acc mean: 0.8457374844539793\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5103692057490833   acc max: 0.8700947221948265\n",
      "loss mean : 0.6504813662449627   acc mean: 0.8136806492594161\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5896910142672723   acc max: 0.8646820103686621\n",
      "loss mean : 0.7548628400409335   acc mean: 0.7810690114341665\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4269523336697012   acc max: 0.8741542664690495\n",
      "loss mean : 0.6493507843830589   acc mean: 0.7922598105088299\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4524613912841141   acc max: 0.8714478941021817\n",
      "loss mean : 0.6885942544448359   acc mean: 0.8042083879373715\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5620340525055448   acc max: 0.8484438360947233\n",
      "loss mean : 0.822036636793565   acc mean: 0.6975372121689767\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6176803583866527   acc max: 0.8497970284886547\n",
      "loss mean : 0.7999745208855732   acc mean: 0.758213801825966\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.31346928742644914   acc max: 0.8917456016811531\n",
      "loss mean : 0.5213870228824983   acc mean: 0.8350338294057628\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3707000831789835   acc max: 0.8903924258216631\n",
      "loss mean : 0.47544236073877877   acc mean: 0.8550067677743062\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.6263533627390055   acc max: 0.8660351846956916\n",
      "loss mean : 0.7451718219433165   acc mean: 0.7047090650350863\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.6087394133311002   acc max: 0.8606224609324671\n",
      "loss mean : 0.7489397551379443   acc mean: 0.7012990529925962\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.40369002220595157   acc max: 0.8714479065231767\n",
      "loss mean : 0.6067690075657687   acc mean: 0.7848985127009783\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3712487829715538   acc max: 0.8673883622489537\n",
      "loss mean : 0.5528394478874051   acc mean: 0.8341542624628755\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.6211652053225185   acc max: 0.8538565603418827\n",
      "loss mean : 0.7546912343648838   acc mean: 0.7121650865516739\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.555331844599547   acc max: 0.7077131265716398\n",
      "loss mean : 0.7869255926329971   acc mean: 0.6598376208725252\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4348131869497415   acc max: 0.872801078430532\n",
      "loss mean : 0.6765532371260639   acc mean: 0.801163733454373\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.44836205905441984   acc max: 0.8741542562257615\n",
      "loss mean : 0.7037469262864657   acc mean: 0.820568335955214\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5902654994001891   acc max: 0.8579161046161058\n",
      "loss mean : 0.7942688784700933   acc mean: 0.7427875489609488\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 16 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7761460837879104   acc max: 0.66035183340674\n",
      "loss mean : 0.9121065782000474   acc mean: 0.5974560217307289\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3164422405992051   acc max: 0.8903924217082166\n",
      "loss mean : 0.4070117865702458   acc mean: 0.8603653574046329\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3154547821443039   acc max: 0.8822733418705982\n",
      "loss mean : 0.43079923933671843   acc mean: 0.8526928276049429\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4143661627185522   acc max: 0.8822733391283006\n",
      "loss mean : 0.5849692296643056   acc mean: 0.8129634644706131\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.47684492850335913   acc max: 0.8741542606618311\n",
      "loss mean : 0.5859783196586396   acc mean: 0.837334234672567\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3737931966942928   acc max: 0.8809201539127365\n",
      "loss mean : 0.5309142643439109   acc mean: 0.82897158105254\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3820132661172276   acc max: 0.8728010821406993\n",
      "loss mean : 0.5000184042088395   acc mean: 0.847726658897245\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.5268586239246942   acc max: 0.8755074361986979\n",
      "loss mean : 0.6738584943464548   acc mean: 0.7843437065129675\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6393397035069652   acc max: 0.8592692904769165\n",
      "loss mean : 0.7819704252642774   acc mean: 0.7345331531238811\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.41117873570109253   acc max: 0.8687415502874712\n",
      "loss mean : 0.6374422167876738   acc mean: 0.8147631934970737\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4172862225762885   acc max: 0.8782137939668637\n",
      "loss mean : 0.6341323186814058   acc mean: 0.8323004060185164\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4589944585089109   acc max: 0.8714478962798886\n",
      "loss mean : 0.7090458447781564   acc mean: 0.750879566309941\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6585702895311606   acc max: 0.8525033738358256\n",
      "loss mean : 0.8509743193158922   acc mean: 0.6665493917729358\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.334370954110916   acc max: 0.8930987857675359\n",
      "loss mean : 0.48351525463012623   acc mean: 0.8500000005371675\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3298203032539404   acc max: 0.8809201632688107\n",
      "loss mean : 0.4546971619838952   acc mean: 0.8503924214186624\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.40764868142479005   acc max: 0.8633288195071911\n",
      "loss mean : 0.5312520081567023   acc mean: 0.8386603515941009\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5764725675279619   acc max: 0.8728010820600435\n",
      "loss mean : 0.6861683108616262   acc mean: 0.8022327464375347\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3202904928601643   acc max: 0.8849796981869595\n",
      "loss mean : 0.511411874039812   acc mean: 0.8395940447216591\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.41036146246048044   acc max: 0.8728010902062805\n",
      "loss mean : 0.5265663041128036   acc mean: 0.8559269315351168\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4871861644300943   acc max: 0.8443843064192023\n",
      "loss mean : 0.6726736960811124   acc mean: 0.7500135323610938\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6847095170911497   acc max: 0.8457374783265574\n",
      "loss mean : 0.7719191162665255   acc mean: 0.6887009469957086\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.45018298454149164   acc max: 0.8755074486196929\n",
      "loss mean : 0.7082204728624979   acc mean: 0.7747767252254225\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4396288519944487   acc max: 0.8673883622489537\n",
      "loss mean : 0.6234970093402552   acc mean: 0.8339918813258614\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.476486217830436   acc max: 0.8755074361986979\n",
      "loss mean : 0.6644285968853432   acc mean: 0.8452232749080625\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5883683597767305   acc max: 0.8700947243725334\n",
      "loss mean : 0.7054595939595256   acc mean: 0.8346278762454432\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2803167303537645   acc max: 0.9012178653631868\n",
      "loss mean : 0.4020532017264702   acc mean: 0.867334235884824\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3197003807847329   acc max: 0.8782138044521193\n",
      "loss mean : 0.43130891492265166   acc mean: 0.8579837622597349\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3684009989479075   acc max: 0.8822733418705982\n",
      "loss mean : 0.502687265060348   acc mean: 0.8269553443301515\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5227382609744194   acc max: 0.8565629248851369\n",
      "loss mean : 0.6127389757220252   acc mean: 0.8439648179490123\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.34613672015792785   acc max: 0.8863328862254771\n",
      "loss mean : 0.490246056338447   acc mean: 0.849269282358909\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3835563928251821   acc max: 0.8836265284573113\n",
      "loss mean : 0.6589843271146446   acc mean: 0.7260487163861324\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5374459295214755   acc max: 0.8376184065545202\n",
      "loss mean : 0.6771010263032293   acc mean: 0.7396617038437091\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.7241697896156001   acc max: 0.6698240895071275\n",
      "loss mean : 0.789747848045358   acc mean: 0.638078483623\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.38208484399625187   acc max: 0.8822733382410868\n",
      "loss mean : 0.6073743821311546   acc mean: 0.816725303029014\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.39090909215045716   acc max: 0.8741542562257615\n",
      "loss mean : 0.6335222165986231   acc mean: 0.8111096068293222\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5160895638440072   acc max: 0.8525033906122345\n",
      "loss mean : 0.6856017064201333   acc mean: 0.7962516916842678\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7164301560115427   acc max: 0.8484438426278441\n",
      "loss mean : 0.8694068632832398   acc mean: 0.6787144787982611\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3031353871054514   acc max: 0.8971583202017499\n",
      "loss mean : 0.42020078145320416   acc mean: 0.8726928279920909\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3362957318193696   acc max: 0.8876860617623439\n",
      "loss mean : 0.4768556871816657   acc mean: 0.8425981050907196\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.41054098552070223   acc max: 0.8822733432417471\n",
      "loss mean : 0.5582601016348528   acc mean: 0.8340324751191921\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4728419313330773   acc max: 0.857916106229222\n",
      "loss mean : 0.5745785986925495   acc mean: 0.8432205697285146\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.3346022241654351   acc max: 0.8903924246118259\n",
      "loss mean : 0.4829428998886007   acc mean: 0.8476048712039185\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.34823365781723403   acc max: 0.8836265138586094\n",
      "loss mean : 0.5408771351124985   acc mean: 0.8448173206588896\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.408869021961589   acc max: 0.8714479021677629\n",
      "loss mean : 0.5393066622770526   acc mean: 0.8526792983313536\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5563439856685386   acc max: 0.8633288223301445\n",
      "loss mean : 0.6986172082274145   acc mean: 0.8125439789606931\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3879630340613596   acc max: 0.8768606285926293\n",
      "loss mean : 0.5633513566670141   acc mean: 0.8346143435004278\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.40438758447786466   acc max: 0.8700947221948265\n",
      "loss mean : 0.6271585743393401   acc mean: 0.8056156964553708\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.43665539411795157   acc max: 0.8782138085655656\n",
      "loss mean : 0.6875931334144693   acc mean: 0.7439648165351158\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 4 , 32 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7073902114318414   acc max: 0.8497970263109478\n",
      "loss mean : 0.8323957989753019   acc mean: 0.6734912014072094\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3514099213444654   acc max: 0.8903924189659191\n",
      "loss mean : 0.5465525891058176   acc mean: 0.8300947213354387\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3354793113123258   acc max: 0.8890392403641315\n",
      "loss mean : 0.5078451671458387   acc mean: 0.860365357086042\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4838198858120445   acc max: 0.8660351794530639\n",
      "loss mean : 0.690392716411244   acc mean: 0.7541677929700953\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5522409513774196   acc max: 0.8741542606618311\n",
      "loss mean : 0.7088462159791721   acc mean: 0.7605006753434512\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3210037099411749   acc max: 0.8890392402834757\n",
      "loss mean : 0.5420284875134493   acc mean: 0.8354939111329225\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.43851493075187536   acc max: 0.8755074361986979\n",
      "loss mean : 0.637892932905154   acc mean: 0.8218809190743347\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5090580154336354   acc max: 0.8673883644266606\n",
      "loss mean : 0.6855222641615164   acc mean: 0.7807713118316518\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.7391337926558778   acc max: 0.6644113733255492\n",
      "loss mean : 0.8305431198993135   acc mean: 0.6471853839181595\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4061729495435026   acc max: 0.8809201663337315\n",
      "loss mean : 0.7093569871593717   acc mean: 0.7671718535028874\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.46377327280051006   acc max: 0.875507446441986\n",
      "loss mean : 0.7423409063357945   acc mean: 0.738782138172764\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6512280969561679   acc max: 0.734776733208735\n",
      "loss mean : 0.8155076194591874   acc mean: 0.6428822755067533\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7509327265503281   acc max: 0.814614344191648\n",
      "loss mean : 0.9476241490111783   acc mean: 0.6145060899160066\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3071210394450873   acc max: 0.8930987816540895\n",
      "loss mean : 0.44403764162963727   acc mean: 0.8574424883545815\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3786657313855317   acc max: 0.8876860617623439\n",
      "loss mean : 0.5567487903203469   acc mean: 0.83778078477744\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.4856111875486955   acc max: 0.8755074406347675\n",
      "loss mean : 0.6519025969541606   acc mean: 0.8209066293938073\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5806028991332719   acc max: 0.8633288222494887\n",
      "loss mean : 0.7686020469673593   acc mean: 0.7594046005828453\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3748959435984311   acc max: 0.8890392343956014\n",
      "loss mean : 0.609445092136063   acc mean: 0.8288768585750148\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3998652384471506   acc max: 0.8809201663337315\n",
      "loss mean : 0.5868290462234991   acc mean: 0.8334641405625498\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.6383312792997399   acc max: 0.8119079886011891\n",
      "loss mean : 0.7812921346524411   acc mean: 0.6505277389981589\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6628030984585598   acc max: 0.8755074383764048\n",
      "loss mean : 0.8367625203329431   acc mean: 0.7087550748753613\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4222067668731545   acc max: 0.875507446441986\n",
      "loss mean : 0.6321860587564632   acc mean: 0.8295534497850318\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5316162540883592   acc max: 0.8714478962798886\n",
      "loss mean : 0.8074128848161041   acc mean: 0.7140324761330357\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.7513509224974254   acc max: 0.6549390989162925\n",
      "loss mean : 0.9210071035755826   acc mean: 0.5838971572061837\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.8111691952396956   acc max: 0.657645465395286\n",
      "loss mean : 0.969293790483023   acc mean: 0.5975507450753039\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.31989568512236477   acc max: 0.88497970568795\n",
      "loss mean : 0.46074112444874077   acc mean: 0.8461299048918672\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3154991342508422   acc max: 0.8985115001746863\n",
      "loss mean : 0.520086071415425   acc mean: 0.8299188077570784\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.40223656197523394   acc max: 0.8917456003100043\n",
      "loss mean : 0.5742146748723778   acc mean: 0.8065493913847794\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5878227903975202   acc max: 0.8687415393989367\n",
      "loss mean : 0.7169987446505259   acc mean: 0.7887821364943164\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.5009580977230821   acc max: 0.8782138063878587\n",
      "loss mean : 0.7807338913198414   acc mean: 0.68610284240808\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.4212976292037835   acc max: 0.8728010843184062\n",
      "loss mean : 0.6385372537612432   acc mean: 0.8068335600868776\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.5338922601914051   acc max: 0.879566976117507\n",
      "loss mean : 0.6901068889764068   acc mean: 0.7334370778974884\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5821160322435815   acc max: 0.8606224623842716\n",
      "loss mean : 0.7365825666440838   acc mean: 0.8139512850785771\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5614786452950257   acc max: 0.8660351881638916\n",
      "loss mean : 0.7838331842995142   acc mean: 0.7717997300868834\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5091801816458954   acc max: 0.8700947163069522\n",
      "loss mean : 0.7507190211482233   acc mean: 0.7582138031967115\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6394868013984618   acc max: 0.8606224602065647\n",
      "loss mean : 0.9198482901454779   acc mean: 0.6319215149191462\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.8268234668468429   acc max: 0.6508795692407714\n",
      "loss mean : 0.9920908514169301   acc mean: 0.532571042131668\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3186791966264722   acc max: 0.8971583202017499\n",
      "loss mean : 0.47818655302584256   acc mean: 0.8569147501811287\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.33304325133279794   acc max: 0.8876860631334926\n",
      "loss mean : 0.5413515866831127   acc mean: 0.8218132598651764\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.6166435336550453   acc max: 0.871447905958586\n",
      "loss mean : 0.7575037699131262   acc mean: 0.7029905285600558\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.7635616230222627   acc max: 0.6576454697506999\n",
      "loss mean : 0.8805898505037952   acc mean: 0.6256292283103496\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.36193602059303664   acc max: 0.8849797106079546\n",
      "loss mean : 0.6647386418897987   acc mean: 0.7849797024096946\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3724816345152255   acc max: 0.8795669900709625\n",
      "loss mean : 0.6583974152375944   acc mean: 0.761840326291218\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4932387596215544   acc max: 0.8741542562257615\n",
      "loss mean : 0.6743678570285699   acc mean: 0.8047496598813789\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.7211256601491058   acc max: 0.8525033906122345\n",
      "loss mean : 0.8482324881022936   acc mean: 0.7147090663703431\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5840976296322917   acc max: 0.8714478941021817\n",
      "loss mean : 0.8078750621506261   acc mean: 0.7784167776245713\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.48662903279832315   acc max: 0.8714479065231767\n",
      "loss mean : 0.7856133512465009   acc mean: 0.7400811893711716\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.6568679128028705   acc max: 0.8606224645619786\n",
      "loss mean : 0.8849854971776956   acc mean: 0.6768606219040444\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7627784740457032   acc max: 0.6522327389704197\n",
      "loss mean : 1.023727670712787   acc mean: 0.5194316636447334\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2922893805336081   acc max: 0.8985115042881326\n",
      "loss mean : 0.4289667368277968   acc mean: 0.8566035182534116\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3821842863611343   acc max: 0.8849797031876199\n",
      "loss mean : 0.5478531731602625   acc mean: 0.8451150205094214\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3864320374228796   acc max: 0.8809201591553643\n",
      "loss mean : 0.5203463887115777   acc mean: 0.8449526400269286\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.46292700734448206   acc max: 0.8673883660397769\n",
      "loss mean : 0.6455590447658452   acc mean: 0.7907442503336801\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.38279208504621326   acc max: 0.8822733484843749\n",
      "loss mean : 0.6111349661779338   acc mean: 0.7961840317149286\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3266417176862208   acc max: 0.886332888403184\n",
      "loss mean : 0.5348331914965129   acc mean: 0.8412043297238376\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4528061223288189   acc max: 0.8903924283219933\n",
      "loss mean : 0.6462594172023792   acc mean: 0.8097699581076552\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5894441087610506   acc max: 0.8646820044807878\n",
      "loss mean : 0.7262166624664457   acc mean: 0.7913261149103811\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4056443392988471   acc max: 0.8782138063878587\n",
      "loss mean : 0.6463175901585083   acc mean: 0.8082138023873305\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4260852274375291   acc max: 0.8822733506620818\n",
      "loss mean : 0.7058186910100815   acc mean: 0.7815020307128256\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5403126513683748   acc max: 0.868741544399597\n",
      "loss mean : 0.7568860847354741   acc mean: 0.7353179973121909\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6775745175204193   acc max: 0.7442489908415829\n",
      "loss mean : 0.8333331175908668   acc mean: 0.6316508798553269\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.3505204835747834   acc max: 0.8903924230793655\n",
      "loss mean : 0.49236162167279424   acc mean: 0.8524086604736172\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3249889049220311   acc max: 0.8944519616270259\n",
      "loss mean : 0.5278651220783975   acc mean: 0.8154397827681248\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.376781882267037   acc max: 0.8768606192365551\n",
      "loss mean : 0.5310200796813701   acc mean: 0.8549797011921949\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5572688840077598   acc max: 0.8660351860668404\n",
      "loss mean : 0.7284676333604548   acc mean: 0.726089309586643\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3829471547161613   acc max: 0.8809201582681504\n",
      "loss mean : 0.6672350939305773   acc mean: 0.7436941800037645\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.49140513298153393   acc max: 0.8768606183493411\n",
      "loss mean : 0.7072157202965514   acc mean: 0.7673883616702482\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3798287970206734   acc max: 0.8836265160363163\n",
      "loss mean : 0.5428093575652945   acc mean: 0.8551826772932594\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6583638117826356   acc max: 0.7780784762115375\n",
      "loss mean : 0.7828640312432275   acc mean: 0.6832070353098909\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.38988753931448167   acc max: 0.8809201560904435\n",
      "loss mean : 0.5841860654736403   acc mean: 0.8274830839033861\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4643713948449198   acc max: 0.879566976117507\n",
      "loss mean : 0.7564934258822337   acc mean: 0.7802435717164097\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4846025272215816   acc max: 0.8673883541833726\n",
      "loss mean : 0.7027356894259847   acc mean: 0.8094993213254642\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6086486459423628   acc max: 0.8646820103686621\n",
      "loss mean : 0.8124030252835425   acc mean: 0.6997564279645964\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.32632324470557444   acc max: 0.8930987816540895\n",
      "loss mean : 0.4709776342616837   acc mean: 0.845331528189621\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30610555595893496   acc max: 0.8985115029169839\n",
      "loss mean : 0.45719487943128256   acc mean: 0.8560081184946798\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.37817102392407004   acc max: 0.8876860617623439\n",
      "loss mean : 0.5383550022080723   acc mean: 0.8404194859976861\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.45942845513114106   acc max: 0.8741542659044589\n",
      "loss mean : 0.6105382857182352   acc mean: 0.8106224635065976\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.32705700800770515   acc max: 0.9093369464106424\n",
      "loss mean : 0.5589417328244939   acc mean: 0.8217050070042379\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3443570347132315   acc max: 0.8876860581328324\n",
      "loss mean : 0.5016464116931446   acc mean: 0.8555074414598763\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4660117022884715   acc max: 0.8782138063878587\n",
      "loss mean : 0.6353355958182691   acc mean: 0.8158051411023156\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6850828300954848   acc max: 0.6630581831093247\n",
      "loss mean : 0.8148599811731073   acc mean: 0.6456698225017169\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4190457167257637   acc max: 0.8822733463066679\n",
      "loss mean : 0.6585380088956333   acc mean: 0.8354803785161493\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.46462203919161643   acc max: 0.875507446441986\n",
      "loss mean : 0.7178952907580322   acc mean: 0.7552909321371212\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5123782578921285   acc max: 0.8673883541833726\n",
      "loss mean : 0.736427395961604   acc mean: 0.808836267844992\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.7742002595100093   acc max: 0.6603518253411589\n",
      "loss mean : 0.9103519884296296   acc mean: 0.6079025717349836\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.30686138253734624   acc max: 0.8944519643693235\n",
      "loss mean : 0.41274856084859424   acc mean: 0.8629499328418737\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.36287786286319224   acc max: 0.8944519588847283\n",
      "loss mean : 0.5365014083358851   acc mean: 0.8402976982035397\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3730591349656592   acc max: 0.8755074406347675\n",
      "loss mean : 0.5028300280084629   acc mean: 0.8436941793649705\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5003602581353246   acc max: 0.8687415421412342\n",
      "loss mean : 0.6784976509959516   acc mean: 0.7776319353675649\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.33257402538124053   acc max: 0.893098788267866\n",
      "loss mean : 0.5515046144749701   acc mean: 0.8277401889959431\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.365201846551508   acc max: 0.8809201604458573\n",
      "loss mean : 0.5347538550377537   acc mean: 0.8362516903078766\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.43796093659084767   acc max: 0.8673883622489537\n",
      "loss mean : 0.6756475654925965   acc mean: 0.7673207024550406\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5105528411265156   acc max: 0.8606224623842716\n",
      "loss mean : 0.7275666618403627   acc mean: 0.8100270629953467\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.44525011361693817   acc max: 0.8741542540480546\n",
      "loss mean : 0.7346167136287173   acc mean: 0.7611637337479605\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3348889113763027   acc max: 0.8809201619783177\n",
      "loss mean : 0.5833760629108375   acc mean: 0.8530581869235381\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.5449694261983219   acc max: 0.8714478941021817\n",
      "loss mean : 0.7763853376345641   acc mean: 0.82005412747597\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 8 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6649399537678823   acc max: 0.8457374907475524\n",
      "loss mean : 0.8686161746933594   acc mean: 0.635669824613286\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3090236560417609   acc max: 0.8985115015458351\n",
      "loss mean : 0.41466417046861165   acc mean: 0.8728416764228044\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.29810687738277913   acc max: 0.8971583229440475\n",
      "loss mean : 0.4226627988199904   acc mean: 0.8788633291993959\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.344903178966739   acc max: 0.8863328831605563\n",
      "loss mean : 0.4880115340672262   acc mean: 0.8538836263674685\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5812256809661772   acc max: 0.870094723243352\n",
      "loss mean : 0.7149850652400146   acc mean: 0.7481596757485676\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3391412810721159   acc max: 0.8836265262796044\n",
      "loss mean : 0.5076807143776118   acc mean: 0.8457780772770209\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.31879799134515135   acc max: 0.8768606242372154\n",
      "loss mean : 0.5003325184280399   acc mean: 0.8421380257263716\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4205896820525194   acc max: 0.8700947302604076\n",
      "loss mean : 0.6075921998214335   acc mean: 0.8000811906281924\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.49060157106758295   acc max: 0.8728010864961131\n",
      "loss mean : 0.6619642090813557   acc mean: 0.8156427594031306\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3453665543876901   acc max: 0.8890392424611826\n",
      "loss mean : 0.5791875085504838   acc mean: 0.8222462780493359\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3780400691319544   acc max: 0.8741542664690495\n",
      "loss mean : 0.5839452266660853   acc mean: 0.8341407301808244\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4342821324710433   acc max: 0.8660351742104361\n",
      "loss mean : 0.6245295040694561   acc mean: 0.8317591331005904\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5596583387203242   acc max: 0.8660351903415985\n",
      "loss mean : 0.800556695943595   acc mean: 0.7842760481127864\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2898179665308683   acc max: 0.9025710414646443\n",
      "loss mean : 0.39804433461253474   acc mean: 0.8784438423770047\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3252309438985481   acc max: 0.8836265204723859\n",
      "loss mean : 0.4350627372955275   acc mean: 0.865209741750896\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3816335069794455   acc max: 0.8849797018164711\n",
      "loss mean : 0.5358381697212892   acc mean: 0.8420027070261631\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.41514676768983005   acc max: 0.8768606258503316\n",
      "loss mean : 0.5547112604479668   acc mean: 0.836617052267143\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3014551860069874   acc max: 0.9012178643953171\n",
      "loss mean : 0.46071496533081235   acc mean: 0.8498240874084629\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.34280607471285396   acc max: 0.8876860705538273\n",
      "loss mean : 0.5002807675852504   acc mean: 0.8476184029613038\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.41064308242965614   acc max: 0.872801076252825\n",
      "loss mean : 0.577445244968986   acc mean: 0.8398646837549539\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.47500249771691144   acc max: 0.8660351822760173\n",
      "loss mean : 0.630310824229527   acc mean: 0.8379161021194053\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4102329450869915   acc max: 0.8673883541833726\n",
      "loss mean : 0.6438044076411907   acc mean: 0.7933423539907427\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.38002118726383205   acc max: 0.8741542540480546\n",
      "loss mean : 0.5943457279347275   acc mean: 0.8070906629218781\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5126542052170905   acc max: 0.8768606264149224\n",
      "loss mean : 0.7335028193921294   acc mean: 0.7669282821655596\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5955436595076637   acc max: 0.8592692802336284\n",
      "loss mean : 0.8178145818781306   acc mean: 0.7651826800093439\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.30131236860006844   acc max: 0.8985115056592815\n",
      "loss mean : 0.40572843025921157   acc mean: 0.875263870138277\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.29293493305475365   acc max: 0.8930987857675359\n",
      "loss mean : 0.4216724987249414   acc mean: 0.866359945947811\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3333890851037589   acc max: 0.8903924203370679\n",
      "loss mean : 0.45286291426549263   acc mean: 0.8571853843319238\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.42659295573124867   acc max: 0.8822733446128959\n",
      "loss mean : 0.5845170238827821   acc mean: 0.8349932343122601\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.2820197455534593   acc max: 0.8903924202564121\n",
      "loss mean : 0.4690739044974558   acc mean: 0.8523274682661838\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3208122993031761   acc max: 0.8876860705538273\n",
      "loss mean : 0.5326654350035729   acc mean: 0.8438700966877769\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3524136978815308   acc max: 0.8836265262796044\n",
      "loss mean : 0.5753286164700582   acc mean: 0.8219079840457488\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4844366639086294   acc max: 0.8714478941021817\n",
      "loss mean : 0.6708982643323756   acc mean: 0.7996887701257799\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.35030385565531913   acc max: 0.8944519682408024\n",
      "loss mean : 0.545780506651037   acc mean: 0.846454670912358\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.34036907577869535   acc max: 0.8809201604458573\n",
      "loss mean : 0.6537663088418312   acc mean: 0.7855886329121695\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4297414808376555   acc max: 0.8660351903415985\n",
      "loss mean : 0.6547070681589059   acc mean: 0.7939512873220187\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5407564135139785   acc max: 0.8579160980829851\n",
      "loss mean : 0.7450515997329166   acc mean: 0.808484437835878\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2870883439164684   acc max: 0.9052774027816659\n",
      "loss mean : 0.3861601576100183   acc mean: 0.869986467816752\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.29820279795197574   acc max: 0.8958051388576647\n",
      "loss mean : 0.44019096813198677   acc mean: 0.8603247609819222\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3721739663887411   acc max: 0.8700947259856496\n",
      "loss mean : 0.5079062517900751   acc mean: 0.8460757799948666\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4841980032411093   acc max: 0.8768606258503316\n",
      "loss mean : 0.6066845913080143   acc mean: 0.8302029786634992\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3356553039466899   acc max: 0.8944519623529282\n",
      "loss mean : 0.4625221218565965   acc mean: 0.8644384327680075\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3486427093713629   acc max: 0.8944519601752213\n",
      "loss mean : 0.5130666120731459   acc mean: 0.8519891760366209\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4079773771262782   acc max: 0.8782138042101518\n",
      "loss mean : 0.5365261984516707   acc mean: 0.8540730688947784\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5022091111407713   acc max: 0.8619756504227892\n",
      "loss mean : 0.6904936871581859   acc mean: 0.7672530451154839\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.4192825728808107   acc max: 0.8755074361986979\n",
      "loss mean : 0.6409916008034966   acc mean: 0.8277807822012936\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3932670014475615   acc max: 0.8809201626235642\n",
      "loss mean : 0.6180880683325786   acc mean: 0.8147225989298507\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4558357188278993   acc max: 0.8795669900709625\n",
      "loss mean : 0.6801161925262785   acc mean: 0.8444249009029466\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 16 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5344492762433982   acc max: 0.8606224602065647\n",
      "loss mean : 0.7944493370699784   acc mean: 0.7417185390761806\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.28825945097635497   acc max: 0.9079837640986875\n",
      "loss mean : 0.38398141683398135   acc mean: 0.8785656295085629\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.29728889295954825   acc max: 0.9012178628628567\n",
      "loss mean : 0.4186232350554937   acc mean: 0.8702706351154391\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.32481804127138264   acc max: 0.8903924230793655\n",
      "loss mean : 0.4389343878267906   acc mean: 0.8645060890396812\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.42615011495730876   acc max: 0.8795669857962044\n",
      "loss mean : 0.534888643215893   acc mean: 0.8537889053526365\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.2952826217885592   acc max: 0.8876860646659531\n",
      "loss mean : 0.4222125095971866   acc mean: 0.8576319342730656\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3305909880846537   acc max: 0.8903924246118259\n",
      "loss mean : 0.4713242217289418   acc mean: 0.8668470895274243\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3418639608342528   acc max: 0.8849797040748338\n",
      "loss mean : 0.5070372158147808   acc mean: 0.8537753703194155\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4126666435853393   acc max: 0.8782137983222775\n",
      "loss mean : 0.6117448362014452   acc mean: 0.8117050064577944\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3226071422332356   acc max: 0.890392422434119\n",
      "loss mean : 0.5076202199931719   acc mean: 0.85374830885048\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.38483108174817005   acc max: 0.8836265182140232\n",
      "loss mean : 0.5819745520164582   acc mean: 0.8278078476062325\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.3999700966078148   acc max: 0.8700947302604076\n",
      "loss mean : 0.6414483611686949   acc mean: 0.799161031073985\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5129887266475228   acc max: 0.8633288164422702\n",
      "loss mean : 0.680236639608711   acc mean: 0.8376725281365671\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3014709684539067   acc max: 0.8998646842610691\n",
      "loss mean : 0.4114128452918526   acc mean: 0.8648714480663026\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2818612620456293   acc max: 0.8998646856322179\n",
      "loss mean : 0.3904835021302244   acc mean: 0.8740866031851595\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3390416275503187   acc max: 0.8930987843963871\n",
      "loss mean : 0.457000514447931   acc mean: 0.862665764509583\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.41283341544568136   acc max: 0.8795669857962044\n",
      "loss mean : 0.5363153233269233   acc mean: 0.8577943182447282\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.2702969377192496   acc max: 0.8985115103373186\n",
      "loss mean : 0.4672309382919208   acc mean: 0.8517726669840626\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.29753426346469153   acc max: 0.8958051503914457\n",
      "loss mean : 0.4198840267728404   acc mean: 0.8630040616393897\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.35087931410224255   acc max: 0.8917455980516416\n",
      "loss mean : 0.5342112862317746   acc mean: 0.8457780763748854\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.40101381979066075   acc max: 0.8849797040748338\n",
      "loss mean : 0.5417211275768539   acc mean: 0.84399188222598\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.30856485158729297   acc max: 0.8903924283219933\n",
      "loss mean : 0.5248113846182016   acc mean: 0.8243843024146412\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4036634834193409   acc max: 0.8782138085655656\n",
      "loss mean : 0.6213514219811224   acc mean: 0.8106630591804184\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.3935618705855977   acc max: 0.8728010821406993\n",
      "loss mean : 0.5915060784779641   acc mean: 0.8386874146813951\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.4647654407885788   acc max: 0.8687415400441831\n",
      "loss mean : 0.6630141510660175   acc mean: 0.8260757771638475\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3340011494730742   acc max: 0.9025710442069419\n",
      "loss mean : 0.43712349863513716   acc mean: 0.8693910691726836\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.31756275706749326   acc max: 0.8985115029169839\n",
      "loss mean : 0.39821498034448843   acc mean: 0.8820433016558947\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.32889054193387013   acc max: 0.8903924217082166\n",
      "loss mean : 0.4478669507561582   acc mean: 0.8598240862526653\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.40535735652475785   acc max: 0.8728010834311922\n",
      "loss mean : 0.5140775002807338   acc mean: 0.8443707710625517\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.33576020614542723   acc max: 0.8863328803376028\n",
      "loss mean : 0.47102515253710975   acc mean: 0.85932341121369\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.30478378218952795   acc max: 0.8985114942061563\n",
      "loss mean : 0.4382451552999521   acc mean: 0.8565493904503819\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3394020999074789   acc max: 0.8903924202564121\n",
      "loss mean : 0.47650008775303926   acc mean: 0.8590257081974184\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.44216886779774833   acc max: 0.875507442086572\n",
      "loss mean : 0.5630224537938148   acc mean: 0.8481055476588065\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3189288585047277   acc max: 0.8944519645306351\n",
      "loss mean : 0.5124422762249577   acc mean: 0.8424763182329875\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3580518733906649   acc max: 0.8890392402834757\n",
      "loss mean : 0.5736237244656831   acc mean: 0.8188768594186748\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4100584797914038   acc max: 0.8809201604458573\n",
      "loss mean : 0.5776304360514404   acc mean: 0.8322056833131387\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.47317090295809694   acc max: 0.875507434020991\n",
      "loss mean : 0.6300377069645547   acc mean: 0.84791609911054\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.27636597334774005   acc max: 0.9039242189372505\n",
      "loss mean : 0.39030279935374146   acc mean: 0.8713937763541091\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3108223529484662   acc max: 0.8998646828899203\n",
      "loss mean : 0.4120775218681005   acc mean: 0.869607575810004\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.32329466511496674   acc max: 0.8930987830252383\n",
      "loss mean : 0.436802530552844   acc mean: 0.864884979194169\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.42806826792002045   acc max: 0.8795669846670231\n",
      "loss mean : 0.5204604289613171   acc mean: 0.8578349137023921\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.2930863603284136   acc max: 0.8958051503914457\n",
      "loss mean : 0.4809944581033735   acc mean: 0.8519891744981113\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.2929997181618165   acc max: 0.901217856329736\n",
      "loss mean : 0.42452368621171244   acc mean: 0.8763734758392238\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3571045305151417   acc max: 0.8849797003646664\n",
      "loss mean : 0.5341122736014597   acc mean: 0.8506359927088062\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.46365749069737805   acc max: 0.8728010740751181\n",
      "loss mean : 0.6441372103370091   acc mean: 0.8124763199400674\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.32560426387961083   acc max: 0.8903924304997002\n",
      "loss mean : 0.5474361302053331   acc mean: 0.8188092032276569\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.3381440240249582   acc max: 0.8849797003646664\n",
      "loss mean : 0.549546400075917   acc mean: 0.8436941799428692\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.47685681366146176   acc max: 0.879566988538502\n",
      "loss mean : 0.6593139528103061   acc mean: 0.7850744251049904\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 8 , 32 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6394284829719141   acc max: 0.7929634587367913\n",
      "loss mean : 0.7872183104530883   acc mean: 0.6627198910140539\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3053388065269093   acc max: 0.8971583243151963\n",
      "loss mean : 0.4301669135125145   acc mean: 0.8736941821717926\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2967818099526494   acc max: 0.8903924203370679\n",
      "loss mean : 0.4542909775748949   acc mean: 0.8593504736137973\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.423812208825745   acc max: 0.8768606219788527\n",
      "loss mean : 0.5807241320452768   acc mean: 0.8259945880358532\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5023561161571007   acc max: 0.864682006093904\n",
      "loss mean : 0.6184282933673613   acc mean: 0.8235588646669026\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.35355440237847974   acc max: 0.8930987743144106\n",
      "loss mean : 0.6027863219957068   acc mean: 0.8123680641118018\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.33550907052418216   acc max: 0.8930987823799917\n",
      "loss mean : 0.5537747343846361   acc mean: 0.8234506112470196\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4451418341980574   acc max: 0.875507446441986\n",
      "loss mean : 0.6224252644790202   acc mean: 0.8228687416486875\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5096272693112675   acc max: 0.8741542642913426\n",
      "loss mean : 0.667056885897226   acc mean: 0.8352097427659493\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.5154503462117805   acc max: 0.8646820066584947\n",
      "loss mean : 0.7237289774611451   acc mean: 0.7266576456584047\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4077303014766218   acc max: 0.8728010740751181\n",
      "loss mean : 0.6635951784019218   acc mean: 0.7973748283699174\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.46378866813986164   acc max: 0.8660351822760173\n",
      "loss mean : 0.6756653448100503   acc mean: 0.7778484433046539\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6418085342653711   acc max: 0.8484438339170164\n",
      "loss mean : 0.8551680341858986   acc mean: 0.6825033832977606\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.29482997794596527   acc max: 0.9039242241798783\n",
      "loss mean : 0.4228649788191579   acc mean: 0.8576860624277544\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.29235424724418835   acc max: 0.8958051429711111\n",
      "loss mean : 0.46737811629238235   acc mean: 0.8353991867845855\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.39588399257647006   acc max: 0.8876860617623439\n",
      "loss mean : 0.5393454026115281   acc mean: 0.8401082555552457\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5118589379468048   acc max: 0.8673883649105955\n",
      "loss mean : 0.6671661820681071   acc mean: 0.7880920158066509\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.33163853076378613   acc max: 0.8903924304997002\n",
      "loss mean : 0.4987220281326238   acc mean: 0.8531123144120101\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3389642808046973   acc max: 0.8836265203917301\n",
      "loss mean : 0.5437347427288798   acc mean: 0.82783491260023\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4584096112819099   acc max: 0.875507444264279\n",
      "loss mean : 0.6598895333277841   acc mean: 0.8232746964717265\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.6313519937582365   acc max: 0.7767253123697635\n",
      "loss mean : 0.7470949590335196   acc mean: 0.666779431259116\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.47056297693749405   acc max: 0.8741542664690495\n",
      "loss mean : 0.768967283338268   acc mean: 0.7752909319346749\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.39545187059694115   acc max: 0.8728010740751181\n",
      "loss mean : 0.6568112416644056   acc mean: 0.8013667109019861\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.589572458531763   acc max: 0.8741542664690495\n",
      "loss mean : 0.7581851505128231   acc mean: 0.6618403253660956\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5978851895048428   acc max: 0.8606224602065647\n",
      "loss mean : 0.7805225150365789   acc mean: 0.8373612986648196\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.3175381532541309   acc max: 0.8985115029169839\n",
      "loss mean : 0.45943989481671094   acc mean: 0.8550067657635562\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.3745040263632799   acc max: 0.8917456003100043\n",
      "loss mean : 0.5763508087816032   acc mean: 0.8140189435944989\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.40586129907664814   acc max: 0.8809201605265131\n",
      "loss mean : 0.5487824854972558   acc mean: 0.8596075763229751\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5219488634308233   acc max: 0.8755074392636187\n",
      "loss mean : 0.7183847486884087   acc mean: 0.7534100135156683\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3226323873812839   acc max: 0.8836265306350182\n",
      "loss mean : 0.550377109444351   acc mean: 0.8249932351966508\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.34201873365048624   acc max: 0.886332888403184\n",
      "loss mean : 0.535784286324323   acc mean: 0.8467659017528348\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.48181890735606864   acc max: 0.8768606161716342\n",
      "loss mean : 0.6531443738711541   acc mean: 0.835439782908063\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5516471115113595   acc max: 0.8741542664690495\n",
      "loss mean : 0.7162277998362891   acc mean: 0.728267929132559\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.36817703764074067   acc max: 0.8782138042101518\n",
      "loss mean : 0.6541956611951568   acc mean: 0.7492016225166022\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.4191350556597497   acc max: 0.8700947265502403\n",
      "loss mean : 0.672304726808013   acc mean: 0.7655615694968075\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5573575115171595   acc max: 0.8592692904769165\n",
      "loss mean : 0.7866613131317943   acc mean: 0.7101353179146213\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6082910706612996   acc max: 0.8538565603418827\n",
      "loss mean : 0.7713452863669039   acc mean: 0.7346684702496888\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.33356059335565375   acc max: 0.8958051429711111\n",
      "loss mean : 0.46824997098786264   acc mean: 0.8446414070732701\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.33687049876369224   acc max: 0.8985115042881326\n",
      "loss mean : 0.46563489438353434   acc mean: 0.8449255750720492\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.4032854008335867   acc max: 0.8930987802829407\n",
      "loss mean : 0.5458193324685742   acc mean: 0.841393774609927\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.5260902994056516   acc max: 0.8579161023577431\n",
      "loss mean : 0.6466461360648134   acc mean: 0.8310825442856478\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.35653774200337507   acc max: 0.8930987823799917\n",
      "loss mean : 0.5025334062627913   acc mean: 0.8520027059018211\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.31628625883301154   acc max: 0.8958051503914457\n",
      "loss mean : 0.4543128103388825   acc mean: 0.8564276056808289\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3864301357201536   acc max: 0.8876860603105393\n",
      "loss mean : 0.5974436049040341   acc mean: 0.7844384302539658\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.5392856244627936   acc max: 0.8619756423572081\n",
      "loss mean : 0.6826405791145862   acc mean: 0.8248173206068666\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.46032095390985717   acc max: 0.8728010740751181\n",
      "loss mean : 0.6920881558045322   acc mean: 0.7794993235737446\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.5313844828386268   acc max: 0.8782138042101518\n",
      "loss mean : 0.7503980889033239   acc mean: 0.8038159689891965\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.5505210914534386   acc max: 0.8714478962798886\n",
      "loss mean : 0.7088351255469779   acc mean: 0.8059675223288582\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 4 , 32 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.6045069519495931   acc max: 0.8592692904769165\n",
      "loss mean : 0.7780605483176097   acc mean: 0.8129093364207766\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.29273681038126087   acc max: 0.9066305827546023\n",
      "loss mean : 0.38304156015746804   acc mean: 0.878755074405541\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.28724621786800225   acc max: 0.8863328817894075\n",
      "loss mean : 0.40125544152175946   acc mean: 0.868119078805224\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3629032799694309   acc max: 0.8795669805535767\n",
      "loss mean : 0.483138728791064   acc mean: 0.8591880927082649\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.4835180513591018   acc max: 0.8836265218435346\n",
      "loss mean : 0.6619750320891246   acc mean: 0.7587821382630986\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.26994418936588765   acc max: 0.8985115066271512\n",
      "loss mean : 0.4225813545796804   acc mean: 0.8648173200749413\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.29863269346815324   acc max: 0.8863328905808909\n",
      "loss mean : 0.4542491192577333   acc mean: 0.8535859276848328\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.32185058608268047   acc max: 0.8849796981869595\n",
      "loss mean : 0.4982203578715073   acc mean: 0.8375507440505716\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.42874991377571114   acc max: 0.8714478941021817\n",
      "loss mean : 0.6347427719791139   acc mean: 0.8095805130743688\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3536392071653606   acc max: 0.8876860603105393\n",
      "loss mean : 0.6183406424478038   acc mean: 0.8118809202986901\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.40806460094226066   acc max: 0.8768606139939273\n",
      "loss mean : 0.6242079734282017   acc mean: 0.8391610280844775\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4804880390389846   acc max: 0.8755074361986979\n",
      "loss mean : 0.7133939553875885   acc mean: 0.7568064940919413\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 4 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.48338461736864907   acc max: 0.8836265262796044\n",
      "loss mean : 0.7037851207867686   acc mean: 0.804722598397522\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.28282184904902485   acc max: 0.9079837588560598\n",
      "loss mean : 0.4040369515556524   acc mean: 0.874736129809297\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2857713754590051   acc max: 0.9093369440716239\n",
      "loss mean : 0.3965024645570086   acc mean: 0.8807713133584665\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3278489877471098   acc max: 0.8876860590200463\n",
      "loss mean : 0.49173478298766354   acc mean: 0.836576456424348\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3580775959404621   acc max: 0.8809201591553643\n",
      "loss mean : 0.5219856729756672   acc mean: 0.853396481939759\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.2961338508435612   acc max: 0.8985115103373186\n",
      "loss mean : 0.4520599253231682   acc mean: 0.8620433001508568\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.29530511004031107   acc max: 0.8917456024070554\n",
      "loss mean : 0.4913006601858687   acc mean: 0.8480649527129046\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.3576971096098826   acc max: 0.8849797084302476\n",
      "loss mean : 0.5098203699232278   acc mean: 0.8506224618898518\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.43191068824153794   acc max: 0.8782137939668637\n",
      "loss mean : 0.6021288323918603   acc mean: 0.8253044659040455\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.33601907137604947   acc max: 0.8863328825153098\n",
      "loss mean : 0.5913356609769539   acc mean: 0.8303112322567923\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.41927476648710094   acc max: 0.8782137983222775\n",
      "loss mean : 0.6619734711128418   acc mean: 0.7676184022620178\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.4658167050075144   acc max: 0.8755074361986979\n",
      "loss mean : 0.6945883867390584   acc mean: 0.7875642748828349\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 8 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.560412121238502   acc max: 0.8673883622489537\n",
      "loss mean : 0.7840714934698139   acc mean: 0.8133558867143844\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss min : 0.318519110769961   acc max: 0.8985115015458351\n",
      "loss mean : 0.4048235417335862   acc mean: 0.8766441122370903\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.30461981457044374   acc max: 0.8890392403641315\n",
      "loss mean : 0.41051989006254125   acc mean: 0.8692422206258259\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.3086880806415104   acc max: 0.8930987802829407\n",
      "loss mean : 0.4596333275410739   acc mean: 0.8483897149199884\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.39608961662355713   acc max: 0.8782138005806402\n",
      "loss mean : 0.5270723356933652   acc mean: 0.8527604869669442\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.32151724815529964   acc max: 0.8917456024070554\n",
      "loss mean : 0.4637300294403778   acc mean: 0.8549255760060435\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3182187415104919   acc max: 0.886332888403184\n",
      "loss mean : 0.5043012788710316   acc mean: 0.8470094710842521\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.34103608421769616   acc max: 0.8728010843184062\n",
      "loss mean : 0.5034696990941149   acc mean: 0.8502571044739267\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 256   Dropout: 0.5\n",
      "loss min : 0.4375366485893162   acc max: 0.868741546577304\n",
      "loss mean : 0.601874621979116   acc mean: 0.8413937728726006\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0\n",
      "loss min : 0.3282536261378509   acc max: 0.8917456024070554\n",
      "loss mean : 0.5305890858774256   acc mean: 0.8337212438548691\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0.1\n",
      "loss min : 0.36841181723126215   acc max: 0.8728010864961131\n",
      "loss mean : 0.6043175217347959   acc mean: 0.823220568365028\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0.3\n",
      "loss min : 0.39710341863767706   acc max: 0.8782138085655656\n",
      "loss mean : 0.5862121564718481   acc mean: 0.8284438431561395\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 16 ]  BatchSize: 512   Dropout: 0.5\n",
      "loss min : 0.5014763486562788   acc max: 0.871447910233344\n",
      "loss mean : 0.7174487551599136   acc mean: 0.8079972944760516\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0\n",
      "loss min : 0.2684663772502352   acc max: 0.8985115029169839\n",
      "loss mean : 0.38589173887676087   acc mean: 0.8635317999781873\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0.1\n",
      "loss min : 0.2705571693803041   acc max: 0.9012178642340055\n",
      "loss mean : 0.39674952103981953   acc mean: 0.8761299033174658\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0.3\n",
      "loss min : 0.28714982530099614   acc max: 0.8958051429711111\n",
      "loss mean : 0.425421596823187   acc mean: 0.8658186740054168\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 128   Dropout: 0.5\n",
      "loss min : 0.3857048674107243   acc max: 0.8836265204723859\n",
      "loss mean : 0.5636602354255354   acc mean: 0.8546684694862818\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0\n",
      "loss min : 0.3130255306444568   acc max: 0.8985115103373186\n",
      "loss mean : 0.44916859589829655   acc mean: 0.8697428967189721\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0.1\n",
      "loss min : 0.3190161132925418   acc max: 0.8903924304997002\n",
      "loss mean : 0.5218517668006869   acc mean: 0.8136129915419872\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0.3\n",
      "loss min : 0.4436006242351377   acc max: 0.8768606139939273\n",
      "loss mean : 0.632812191032589   acc mean: 0.7708254371581443\n",
      "\n",
      "Activation: relu   Loss: categorical_crossentropy   HiddenLayer: 2   Node:[ 16 , 8 , 32 ]  BatchSize: 256   Dropout: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "actiFunc = ['relu', 'sigmoid', 'elu', 'selu']\n",
    "lossFunc = ['categorical_crossentropy']\n",
    "hidden = [1, 2, 3]\n",
    "#node = [[4, 4], [4, 8], [4, 16], [4, 32], [8, 4], [8, 8], [8, 16], [8, 32], [16, 4], [16, 8], [16, 16], [16, 32], [32, 4], [32, 8], [32, 16], [32, 32]]\n",
    "node = [\n",
    "    [4, 4, 4], [4, 4, 8], [4, 4, 16], [4, 4, 32], [4, 8, 4], [4, 8, 8], [4, 8, 16], [4, 8, 32], [4, 16, 4], [4, 16, 8], [4, 16, 16], [4, 16, 32], [4, 32, 4], [4, 32, 8], [4, 32, 16], [4, 32, 32],\n",
    "    [8, 4, 4], [8, 4, 8], [8, 4, 16], [8, 4, 32], [8, 8, 4], [8, 8, 8], [8, 8, 16], [8, 8, 32], [8, 16, 4], [8, 16, 8], [8, 16, 16], [8, 16, 32], [8, 32, 4], [8, 32, 8], [8, 32, 16], [8, 32, 32],\n",
    "    [16, 4, 4], [16, 4, 8], [16, 4, 16], [16, 4, 32], [16, 8, 4], [16, 8, 8], [16, 8, 16], [16, 8, 32], [16, 16, 4], [16, 16, 8], [16, 16, 16], [16, 16, 32], [16, 32, 4], [16, 32, 8], [16, 32, 16], [16, 32, 32],\n",
    "    [32, 4, 4], [32, 4, 8], [32, 4, 16], [32, 4, 32], [32, 8, 4], [32, 8, 8], [32, 8, 16], [32, 8, 32], [32, 16, 4], [32, 16, 8], [32, 16, 16], [32, 16, 32], [32, 32, 4], [32, 32, 8], [32, 32, 16], [32, 32, 32]\n",
    "]\n",
    "batchSize = [128, 256, 512]\n",
    "dropout = [0, 0.1, 0.3, 0.5]\n",
    "\n",
    "all_acc_histories = []\n",
    "all_loss_histories = []\n",
    "\n",
    "for i in range(len(actiFunc)):\n",
    "    for j in range(len(lossFunc)):\n",
    "        for k in range(len(hidden)):\n",
    "            for l in range(len(node)):\n",
    "                for m in range(len(batchSize)):\n",
    "                    for n in range(len(dropout)):\n",
    "                        print('Activation:', actiFunc[i] , '  Loss:', lossFunc[j] , '  HiddenLayer:', hidden[k] , '  Node:[', node[l][0], ',', node[l][1] , ',', node[l][2], ']  BatchSize:', batchSize[m], '  Dropout:', dropout[n])\n",
    "    \n",
    "                        model = build_model(actiFunc[i], lossFunc[j], hidden[k], node[l], dropout[n])\n",
    "                        history = model.fit(train_data, train_label, validation_data=(val_data, val_label), epochs=num_epochs, batch_size=batchSize[m], verbose=False)\n",
    "    \n",
    "                        acc_history = history.history['val_acc']\n",
    "                        all_acc_histories.append(acc_history)\n",
    "                        loss_history = history.history['val_loss']\n",
    "                        all_loss_histories.append(loss_history)\n",
    "    \n",
    "                        print('loss min :', min(loss_history), '  acc max:', max(acc_history))\n",
    "                        print('loss mean :', np.mean(loss_history), '  acc mean:', np.mean(acc_history))\n",
    "    \n",
    "                        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
